# RUN: llc %s -O3 -fswp -swpl-minii=5 -mcpu=a64fx -start-before=aarch64-swpipeliner -pass-remarks=aarch64-swpipeliner -swpl-reg-alloc-prio=1 -swpl-debug -o /dev/null 2>&1 | FileCheck %s
# CHECK:        : (Iterative Modulo Scheduling. ResMII 4. NumOfBodyInsts 14. Budget 700. Minimum II = 5.)
# CHECK-NEXT:DBG(SwplTrialState::tryNext) gave up scheduling because it was arranged across more than 20 stages.(II=5)
# CHECK-NEXT:        :  (x) Run out of budget      at estimation.          : (II: 5 in [ 5,1000]) MVE: 0 Last inst: 3. (Itr Org: 0, Req: 0) (VReg Fp: 0/0, Int: 0/0, Pre: 0/0) Eval:0.000000e+00.
# CHECK-NEXT:        :  (O) Scheduling succeeds    at estimation.          : (II: 6 in [ 5,1000]) MVE: 5 Last inst: 0. (Itr Org: 0, Req: 11) (VReg Fp: 24/32, Int: 8/29, Pre: 1/8) Eval:0.000000e+00.
# CHECK-NEXT:        : Required iteration count in MIR input is        :   11 (= kernel:5 + pro/epilogue:6 + mod:0)
# CHECK-NEXT:        : Original loop iteration is not found.
# CHECK-NEXT:        : Reschedule with minii set to 7 because ran out of physical registers.
# CHECK-NEXT:        : (Iterative Modulo Scheduling. ResMII 4. NumOfBodyInsts 14. Budget 700. Minimum II = 7.)
# CHECK-NEXT:        :  (O) Scheduling succeeds    at estimation.          : (II: 7 in [ 7,1000]) MVE: 4 Last inst: 0. (Itr Org: 0, Req: 9) (VReg Fp: 20/32, Int: 8/29, Pre: 1/8) Eval:0.000000e+00.
# CHECK-NEXT:        : Required iteration count in MIR input is        :   9 (= kernel:4 + pro/epilogue:5 + mod:0)
# CHECK-NEXT:        : Original loop iteration is not found.
# CHECK-NEXT:remark: <unknown>:0:0: software pipelining (IPC: 2.00, ITR: 9, MVE: 4, II: 7, Stage: 6, (VReg Fp: 20/32, Int: 8/29, Pred: 1/8)), SRA(PReg Fp: 18/32, Int: 6/29, Pred: 0/8)

--- |
  ; ModuleID = 'a.c'
  source_filename = "a.c"
  target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
  target triple = "aarch64-unknown-linux-gnu"
  
  @c = external local_unnamed_addr global [32000 x double], align 64
  @b = external local_unnamed_addr global [32000 x double], align 64
  @d = external local_unnamed_addr global [32000 x double], align 64
  @a = external local_unnamed_addr global [32000 x double], align 64
  
  ; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, argmem: none, inaccessiblemem: none) uwtable vscale_range(1,16)
  define dso_local void @s() local_unnamed_addr #0 {
  entry:
    %0 = tail call i64 @llvm.vscale.i64()
    %1 = shl nuw nsw i64 %0, 1
    %n.mod.vf = urem i64 16000, %1
    %n.vec = sub i64 16000, %n.mod.vf
    %2 = tail call <vscale x 2 x i64> @llvm.experimental.stepvector.nxv2i64()
    %3 = tail call i64 @llvm.vscale.i64()
    %4 = shl nuw nsw i64 %3, 1
    %.splatinsert = insertelement <vscale x 2 x i64> poison, i64 %4, i64 0
    %.splat = shufflevector <vscale x 2 x i64> %.splatinsert, <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer
    %5 = tail call i64 @llvm.vscale.i64()
    %6 = shl nuw nsw i64 %5, 1
    %7 = udiv i64 16000, %1
    %8 = mul i64 %0, %7
    %9 = shl i64 %8, 4
    %uglygep59 = getelementptr i8, ptr @d, i64 %9
    %uglygep61 = getelementptr i8, ptr @b, i64 %9
    %uglygep64 = getelementptr i8, ptr @c, i64 %9
    %10 = mul i64 %0, %7
    %11 = shl i64 %10, 5
    %uglygep67 = getelementptr i8, ptr @a, i64 %11
    br label %vector.ph
  
  vector.ph:                                        ; preds = %for.cond.cleanup3, %entry
    %nl.051 = phi i32 [ 0, %entry ], [ %inc34, %for.cond.cleanup3 ]
    br label %vector.body
  
  vector.body:                                      ; preds = %vector.body, %vector.ph
    %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
    %vec.ind = phi <vscale x 2 x i64> [ %2, %vector.ph ], [ %vec.ind.next, %vector.body ]
    %12 = shl i64 %index, 3
    %uglygep = getelementptr i8, ptr @c, i64 %12
    %wide.load = load <vscale x 2 x double>, ptr %uglygep, align 16, !tbaa !6
    %uglygep57 = getelementptr i8, ptr @b, i64 %12
    %wide.load55 = load <vscale x 2 x double>, ptr %uglygep57, align 16, !tbaa !6
    %13 = shl i64 %index, 3
    %uglygep58 = getelementptr i8, ptr @d, i64 %13
    %wide.load56 = load <vscale x 2 x double>, ptr %uglygep58, align 16, !tbaa !6
    %14 = fmul fast <vscale x 2 x double> %wide.load55, shufflevector (<vscale x 2 x double> insertelement (<vscale x 2 x double> poison, double 2.000000e+00, i64 0), <vscale x 2 x double> poison, <vscale x 2 x i32> zeroinitializer)
    %15 = fmul fast <vscale x 2 x double> %14, %wide.load56
    %16 = fadd fast <vscale x 2 x double> %wide.load55, %wide.load
    %17 = fadd fast <vscale x 2 x double> %16, %wide.load56
    %18 = fmul fast <vscale x 2 x double> %17, %wide.load
    %19 = fadd fast <vscale x 2 x double> %18, %15
    %20 = shl nuw nsw <vscale x 2 x i64> %vec.ind, shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 1, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer)
    %21 = getelementptr double, ptr @a, <vscale x 2 x i64> %20
    tail call void @llvm.masked.scatter.nxv2f64.nxv2p0(<vscale x 2 x double> %19, <vscale x 2 x ptr> %21, i32 16, <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer)), !tbaa !6
    %index.next = add nuw i64 %index, %6
    %vec.ind.next = add <vscale x 2 x i64> %vec.ind, %.splat
    %22 = icmp eq i64 %n.vec, %index.next
    br i1 %22, label %middle.block, label %vector.body, !llvm.loop !10
  
  middle.block:                                     ; preds = %vector.body
    %23 = icmp eq i64 %n.mod.vf, 0
    br i1 %23, label %for.cond.cleanup3, label %for.body4.preheader
  
  for.body4.preheader:                              ; preds = %middle.block
    %24 = call i64 @llvm.start.loop.iterations.i64(i64 %n.mod.vf)
    br label %for.body4
  
  for.cond.cleanup:                                 ; preds = %for.cond.cleanup3
    ret void
  
  for.cond.cleanup3:                                ; preds = %for.body4, %middle.block
    %inc34 = add nuw nsw i32 %nl.051, 1
    %exitcond54.not = icmp eq i32 %inc34, 200000
    br i1 %exitcond54.not, label %for.cond.cleanup, label %vector.ph, !llvm.loop !14
  
  for.body4:                                        ; preds = %for.body4.preheader, %for.body4
    %lsr.iv68 = phi ptr [ %uglygep67, %for.body4.preheader ], [ %uglygep69, %for.body4 ]
    %lsr.iv65 = phi ptr [ %uglygep64, %for.body4.preheader ], [ %uglygep66, %for.body4 ]
    %lsr.iv62 = phi ptr [ %uglygep61, %for.body4.preheader ], [ %uglygep63, %for.body4 ]
    %lsr.iv = phi ptr [ %uglygep59, %for.body4.preheader ], [ %uglygep60, %for.body4 ]
    %25 = phi i64 [ %24, %for.body4.preheader ], [ %29, %for.body4 ]
    %26 = load double, ptr %lsr.iv65, align 8, !tbaa !6
    %27 = load double, ptr %lsr.iv62, align 8, !tbaa !6
    %28 = load double, ptr %lsr.iv, align 8, !tbaa !6
    %mul11 = fmul fast double %27, 2.000000e+00
    %factor = fmul fast double %mul11, %28
    %reass.add = fadd fast double %27, %26
    %reass.add49 = fadd fast double %reass.add, %28
    %reass.mul = fmul fast double %reass.add49, %26
    %add29 = fadd fast double %reass.mul, %factor
    store double %add29, ptr %lsr.iv68, align 16, !tbaa !6
    %uglygep60 = getelementptr i8, ptr %lsr.iv, i64 8
    %uglygep63 = getelementptr i8, ptr %lsr.iv62, i64 8
    %uglygep66 = getelementptr i8, ptr %lsr.iv65, i64 8
    %uglygep69 = getelementptr i8, ptr %lsr.iv68, i64 16
    %29 = call i64 @llvm.loop.decrement.reg.i64(i64 %25, i64 1)
    %30 = icmp ne i64 %29, 0
    br i1 %30, label %for.body4, label %for.cond.cleanup3, !llvm.loop !15
  }
  
  ; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
  declare i64 @llvm.vscale.i64() #1
  
  ; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
  declare <vscale x 2 x i64> @llvm.experimental.stepvector.nxv2i64() #1
  
  ; Function Attrs: nocallback nofree nosync nounwind willreturn memory(write)
  declare void @llvm.masked.scatter.nxv2f64.nxv2p0(<vscale x 2 x double>, <vscale x 2 x ptr>, i32 immarg, <vscale x 2 x i1>) #2
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.start.loop.iterations.i64(i64) #3
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.loop.decrement.reg.i64(i64, i64) #3
  
  attributes #0 = { nofree norecurse nosync nounwind memory(readwrite, argmem: none, inaccessiblemem: none) uwtable vscale_range(1,16) "approx-func-fp-math"="true" "frame-pointer"="non-leaf" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+crypto,+fp-armv8,+fullfp16,+lse,+neon,+outline-atomics,+ras,+rdm,+sha2,+sve,+v8.1a,+v8.2a,+v8a,-fmv" "unsafe-fp-math"="true" }
  attributes #1 = { nocallback nofree nosync nounwind willreturn memory(none) }
  attributes #2 = { nocallback nofree nosync nounwind willreturn memory(write) }
  attributes #3 = { nocallback noduplicate nofree nosync nounwind willreturn }
  
  !llvm.module.flags = !{!0, !1, !2, !3, !4}
  !llvm.ident = !{!5}
  
  !0 = !{i32 1, !"wchar_size", i32 4}
  !1 = !{i32 8, !"PIC Level", i32 2}
  !2 = !{i32 7, !"PIE Level", i32 2}
  !3 = !{i32 7, !"uwtable", i32 2}
  !4 = !{i32 7, !"frame-pointer", i32 1}
  !5 = !{!"clang version 16.0.6 ()"}
  !6 = !{!7, !7, i64 0}
  !7 = !{!"double", !8, i64 0}
  !8 = !{!"omnipotent char", !9, i64 0}
  !9 = !{!"Simple C/C++ TBAA"}
  !10 = distinct !{!10, !11, !12, !13}
  !11 = !{!"llvm.loop.mustprogress"}
  !12 = !{!"llvm.loop.isvectorized", i32 1}
  !13 = !{!"llvm.loop.unroll.runtime.disable"}
  !14 = distinct !{!14, !11}
  !15 = distinct !{!15, !11, !13, !12}

...
---
name:            s
alignment:       8
exposesReturnsTwice: false
legalized:       false
regBankSelected: false
selected:        false
failedISel:      false
tracksRegLiveness: true
hasWinCFI:       false
callsEHReturn:   false
callsUnwindInit: false
hasEHCatchret:   false
hasEHScopes:     false
hasEHFunclets:   false
debugInstrRef:   false
failsVerification: false
tracksDebugUserValues: false
registers:
  - { id: 0, class: gpr64, preferred-register: '' }
  - { id: 1, class: gpr64, preferred-register: '' }
  - { id: 2, class: zpr, preferred-register: '' }
  - { id: 3, class: zpr, preferred-register: '' }
  - { id: 4, class: gpr64, preferred-register: '' }
  - { id: 5, class: gpr64all, preferred-register: '' }
  - { id: 6, class: gpr64all, preferred-register: '' }
  - { id: 7, class: gpr64all, preferred-register: '' }
  - { id: 8, class: gpr64all, preferred-register: '' }
  - { id: 9, class: gpr32sp, preferred-register: '' }
  - { id: 10, class: gpr64common, preferred-register: '' }
  - { id: 11, class: zpr, preferred-register: '' }
  - { id: 12, class: gpr64all, preferred-register: '' }
  - { id: 13, class: zpr, preferred-register: '' }
  - { id: 14, class: gpr64all, preferred-register: '' }
  - { id: 15, class: gpr32all, preferred-register: '' }
  - { id: 16, class: gpr64sp, preferred-register: '' }
  - { id: 17, class: gpr64sp, preferred-register: '' }
  - { id: 18, class: gpr64sp, preferred-register: '' }
  - { id: 19, class: gpr64sp, preferred-register: '' }
  - { id: 20, class: gpr64sp, preferred-register: '' }
  - { id: 21, class: gpr64all, preferred-register: '' }
  - { id: 22, class: gpr64all, preferred-register: '' }
  - { id: 23, class: gpr64all, preferred-register: '' }
  - { id: 24, class: gpr64all, preferred-register: '' }
  - { id: 25, class: gpr64all, preferred-register: '' }
  - { id: 26, class: gpr32all, preferred-register: '' }
  - { id: 27, class: gpr64, preferred-register: '' }
  - { id: 28, class: gpr64, preferred-register: '' }
  - { id: 29, class: gpr64common, preferred-register: '' }
  - { id: 30, class: gpr32sp, preferred-register: '' }
  - { id: 31, class: gpr32common, preferred-register: '' }
  - { id: 32, class: gpr64, preferred-register: '' }
  - { id: 33, class: gpr64all, preferred-register: '' }
  - { id: 34, class: gpr32, preferred-register: '' }
  - { id: 35, class: gpr64, preferred-register: '' }
  - { id: 36, class: gpr64, preferred-register: '' }
  - { id: 37, class: gpr64, preferred-register: '' }
  - { id: 38, class: gpr64, preferred-register: '' }
  - { id: 39, class: gpr64, preferred-register: '' }
  - { id: 40, class: gpr64, preferred-register: '' }
  - { id: 41, class: gpr64common, preferred-register: '' }
  - { id: 42, class: gpr64, preferred-register: '' }
  - { id: 43, class: gpr64common, preferred-register: '' }
  - { id: 44, class: gpr64, preferred-register: '' }
  - { id: 45, class: gpr64common, preferred-register: '' }
  - { id: 46, class: gpr64, preferred-register: '' }
  - { id: 47, class: gpr64common, preferred-register: '' }
  - { id: 48, class: gpr64, preferred-register: '' }
  - { id: 49, class: gpr32all, preferred-register: '' }
  - { id: 50, class: gpr64all, preferred-register: '' }
  - { id: 51, class: gpr64all, preferred-register: '' }
  - { id: 52, class: gpr64common, preferred-register: '' }
  - { id: 53, class: ppr_3b, preferred-register: '' }
  - { id: 54, class: zpr, preferred-register: '' }
  - { id: 55, class: gpr64common, preferred-register: '' }
  - { id: 56, class: zpr, preferred-register: '' }
  - { id: 57, class: gpr64common, preferred-register: '' }
  - { id: 58, class: zpr, preferred-register: '' }
  - { id: 59, class: zpr, preferred-register: '' }
  - { id: 60, class: zpr, preferred-register: '' }
  - { id: 61, class: zpr, preferred-register: '' }
  - { id: 62, class: zpr, preferred-register: '' }
  - { id: 63, class: ppr_3b, preferred-register: '' }
  - { id: 64, class: zpr, preferred-register: '' }
  - { id: 65, class: zpr, preferred-register: '' }
  - { id: 66, class: gpr64common, preferred-register: '' }
  - { id: 67, class: gpr64, preferred-register: '' }
  - { id: 68, class: gpr64, preferred-register: '' }
  - { id: 69, class: gpr64sp, preferred-register: '' }
  - { id: 70, class: fpr64, preferred-register: '' }
  - { id: 71, class: gpr64sp, preferred-register: '' }
  - { id: 72, class: fpr64, preferred-register: '' }
  - { id: 73, class: gpr64sp, preferred-register: '' }
  - { id: 74, class: fpr64, preferred-register: '' }
  - { id: 75, class: fpr64, preferred-register: '' }
  - { id: 76, class: fpr64, preferred-register: '' }
  - { id: 77, class: fpr64, preferred-register: '' }
  - { id: 78, class: fpr64, preferred-register: '' }
  - { id: 79, class: fpr64, preferred-register: '' }
  - { id: 80, class: fpr64, preferred-register: '' }
  - { id: 81, class: gpr64sp, preferred-register: '' }
  - { id: 82, class: gpr64, preferred-register: '' }
  - { id: 83, class: gpr32common, preferred-register: '' }
  - { id: 84, class: gpr32, preferred-register: '' }
  - { id: 85, class: gpr32, preferred-register: '' }
  - { id: 86, class: zpr, preferred-register: '' }
  - { id: 87, class: zpr, preferred-register: '' }
  - { id: 88, class: fpr64, preferred-register: '' }
  - { id: 89, class: fpr64, preferred-register: '' }
liveins:         []
frameInfo:
  isFrameAddressTaken: false
  isReturnAddressTaken: false
  hasStackMap:     false
  hasPatchPoint:   false
  stackSize:       0
  offsetAdjustment: 0
  maxAlignment:    1
  adjustsStack:    false
  hasCalls:        false
  stackProtector:  ''
  functionContext: ''
  maxCallFrameSize: 0
  cvBytesOfCalleeSavedRegisters: 0
  hasOpaqueSPAdjustment: false
  hasVAStart:      false
  hasMustTailInVarArgFunc: false
  hasTailCall:     false
  localFrameSize:  0
  savePoint:       ''
  restorePoint:    ''
fixedStack:      []
stack:           []
callSites:       []
debugValueSubstitutions: []
constants:       []
machineFunctionInfo: {}
body:             |
  bb.0.entry:
    successors: %bb.1(0x80000000)
  
    %27:gpr64 = RDVLI_XI 1
    %28:gpr64 = UBFMXri killed %27, 4, 63
    %29:gpr64common = CNTD_XPiI 31, 1
    %30:gpr32sp = COPY %29.sub_32
    %31:gpr32common = SUBWri killed %30, 1, 0
    %33:gpr64all = IMPLICIT_DEF
    %32:gpr64 = SUBREG_TO_REG 0, killed %31, %subreg.sub_32
    %34:gpr32 = MOVi32imm 16000
    %35:gpr64 = SUBREG_TO_REG 0, killed %34, %subreg.sub_32
    %36:gpr64 = ANDXrr killed %32, %35
    %0:gpr64 = COPY %36
    %37:gpr64 = EORXrr %36, %35
    %2:zpr = INDEX_II_D 0, 1
    %3:zpr = DUP_ZR_D %29
    %38:gpr64 = UDIVXr %35, %29
    %39:gpr64 = MADDXrrr killed %28, killed %38, $xzr
    %40:gpr64 = UBFMXri %39, 60, 59
    %41:gpr64common = LOADgot target-flags(aarch64-got) @d
    %42:gpr64 = ADDXrr %41, %40
    %5:gpr64all = COPY %42
    %43:gpr64common = LOADgot target-flags(aarch64-got) @b
    %44:gpr64 = ADDXrr %43, %40
    %6:gpr64all = COPY %44
    %45:gpr64common = LOADgot target-flags(aarch64-got) @c
    %46:gpr64 = ADDXrr %45, %40
    %7:gpr64all = COPY %46
    %47:gpr64common = LOADgot target-flags(aarch64-got) @a
    %48:gpr64 = ADDXrs %47, %39, 5
    %49:gpr32all = COPY $wzr
    %26:gpr32all = COPY %49
    %8:gpr64all = COPY %48
    %53:ppr_3b = PTRUE_D 31
    %84:gpr32 = MOVi32imm 200000
  
  bb.1.vector.ph:
    successors: %bb.2(0x80000000)
  
    %9:gpr32sp = PHI %26, %bb.0, %15, %bb.6
    %51:gpr64all = COPY $xzr
    %50:gpr64all = COPY %51
  
  bb.2.vector.body:
    successors: %bb.3(0x04000000), %bb.2(0x7c000000)
  
    %10:gpr64common = PHI %50, %bb.1, %12, %bb.2
    %11:zpr = PHI %2, %bb.1, %13, %bb.2
    %54:zpr = LD1D %53, %45, %10 :: (load unknown-size from %ir.uglygep, align 16, !tbaa !6)
    %56:zpr = LD1D %53, %43, %10 :: (load unknown-size from %ir.uglygep57, align 16, !tbaa !6)
    %58:zpr = LD1D %53, %41, %10 :: (load unknown-size from %ir.uglygep58, align 16, !tbaa !6)
    %59:zpr = nnan ninf nsz arcp contract afn reassoc FADD_ZZZ_D %58, %58
    %60:zpr = nnan ninf nsz arcp contract afn reassoc FMUL_ZZZ_D %56, killed %59
    %61:zpr = nnan ninf nsz arcp contract afn reassoc FADD_ZZZ_D %56, %54
    %62:zpr = nnan ninf nsz arcp contract afn reassoc FADD_ZZZ_D killed %61, %58
    %64:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_D_UNDEF %53, killed %60, killed %62, %54
    %65:zpr = nuw nsw LSL_ZZI_D %11, 1
    SST1D_SCALED killed %64, %53, %47, killed %65 :: (store unknown-size, align 16, !tbaa !6)
    %67:gpr64 = nuw ADDXrr %10, %29
    %12:gpr64all = COPY %67
    %13:zpr = ADD_ZZZ_D %11, %3
    dead $xzr = SUBSXrr %37, %67, implicit-def $nzcv
    Bcc 1, %bb.2, implicit $nzcv
    B %bb.3
  
  bb.3.middle.block:
    successors: %bb.6(0x30000000), %bb.4(0x50000000)
  
    CBZX %0, %bb.6
    B %bb.4
  
  bb.4.for.body4.preheader:
    successors: %bb.7(0x80000000)
  
    %14:gpr64all = COPY %0
    B %bb.7
  
  bb.5.for.cond.cleanup:
    RET_ReallyLR
  
  bb.6.for.cond.cleanup3:
    successors: %bb.5(0x04000000), %bb.1(0x7c000000)
  
    %83:gpr32common = nuw nsw ADDWri %9, 1, 0
    %15:gpr32all = COPY %83
    dead $wzr = SUBSWrr %83, %84, implicit-def $nzcv
    Bcc 0, %bb.5, implicit $nzcv
    B %bb.1
  
  bb.7.for.body4:
    successors: %bb.7(0x7c000000), %bb.6(0x04000000)
  
    %16:gpr64sp = PHI %8, %bb.4, %24, %bb.7
    %17:gpr64sp = PHI %7, %bb.4, %23, %bb.7
    %18:gpr64sp = PHI %6, %bb.4, %22, %bb.7
    %19:gpr64sp = PHI %5, %bb.4, %21, %bb.7
    %20:gpr64sp = PHI %14, %bb.4, %25, %bb.7
    early-clobber %69:gpr64sp, %70:fpr64 = LDRDpost %17, 8 :: (load (s64) from %ir.lsr.iv65, !tbaa !6)
    early-clobber %71:gpr64sp, %72:fpr64 = LDRDpost %18, 8 :: (load (s64) from %ir.lsr.iv62, !tbaa !6)
    early-clobber %73:gpr64sp, %74:fpr64 = LDRDpost %19, 8 :: (load (s64) from %ir.lsr.iv, !tbaa !6)
    %75:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FADDDrr %74, %74, implicit $fpcr
    %76:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %72, killed %75, implicit $fpcr
    %77:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FADDDrr %72, %70, implicit $fpcr
    %78:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FADDDrr killed %77, %74, implicit $fpcr
    %80:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMADDDrrr killed %78, %70, killed %76, implicit $fpcr
    early-clobber %81:gpr64sp = STRDpost killed %80, %16, 16 :: (store (s64) into %ir.lsr.iv68, align 16, !tbaa !6)
    %21:gpr64all = COPY %73
    %22:gpr64all = COPY %71
    %23:gpr64all = COPY %69
    %24:gpr64all = COPY %81
    %82:gpr64 = SUBSXri %20, 1, 0, implicit-def $nzcv
    %25:gpr64all = COPY %82
    Bcc 1, %bb.7, implicit $nzcv
    B %bb.6

...
