# RUN: llc %s -O3 -fswp -mcpu=a64fx -start-before=aarch64-swpipeliner -swpl-reg-alloc-prio=1 -swpl-debug -o /dev/null 2>&1 | FileCheck %s
# CHECK:        : (Iterative Modulo Scheduling. ResMII 69. NumOfBodyInsts 138. Budget 3450. II 111. Minimum II = 111.)
# CHECK-NEXT:        :  (O) Scheduling succeeds    at estimation.          : (II: 111 in [ 111,112]) MVE: 2 Last inst: 0. (Itr Org: 711, Req: 3) (VReg Fp: 18/32, Int: 4/29, Pre: 1/8) Eval:0.000000e+00.
# CHECK-NEXT:        : Required iteration count in MIR input is        :   3 (= kernel:2 + pro/epilogue:1 + mod:0)
# CHECK-NEXT:        : Original iteration count in MIR is found        :   711
# CHECK-NEXT:        :      Non-tuned SWPL (ker exp, ker itr, mod itr) : ( 2, 355, 0)
# CHECK-NEXT:        : No rescheduling because II is specified in the pragma.

--- |
  ; ModuleID = 'a.c'
  source_filename = "a.c"
  target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
  target triple = "aarch64-unknown-linux-gnu"
  
  @a = external local_unnamed_addr global [32000 x double], align 64
  
  ; Function Attrs: nofree norecurse nosync nounwind memory(readwrite, argmem: none, inaccessiblemem: none) uwtable vscale_range(1,16)
  define dso_local void @s() local_unnamed_addr #0 {
  entry:
    br label %for.cond1.preheader
  
  for.cond1.preheader:                              ; preds = %entry, %for.cond.cleanup3
    %nl.070 = phi i32 [ 0, %entry ], [ %inc, %for.cond.cleanup3 ]
    %.pre = load double, ptr @a, align 64, !tbaa !6
    %0 = call i64 @llvm.start.loop.iterations.i64(i64 711)
    br label %for.body4
  
  for.cond.cleanup:                                 ; preds = %for.cond.cleanup3
    ret void
  
  for.cond.cleanup3:                                ; preds = %for.body4
    %inc = add nuw nsw i32 %nl.070, 1
    %exitcond.not = icmp eq i32 %inc, 1000000
    br i1 %exitcond.not, label %for.cond.cleanup, label %for.cond1.preheader, !llvm.loop !10
  
  for.body4:                                        ; preds = %for.body4, %for.cond1.preheader
    %lsr.iv76 = phi ptr [ %uglygep, %for.body4 ], [ getelementptr inbounds ([32000 x double], ptr @a, i64 0, i64 23), %for.cond1.preheader ]
    %1 = phi double [ %.pre, %for.cond1.preheader ], [ %47, %for.body4 ]
    %2 = phi i64 [ %0, %for.cond1.preheader ], [ %48, %for.body4 ]
    %uglygep81 = getelementptr i8, ptr %lsr.iv76, i64 -176
    %3 = load double, ptr %uglygep81, align 8, !tbaa !6
    %uglygep77 = getelementptr i8, ptr %lsr.iv76, i64 -184
    %mul = fmul fast double %1, %3
    store double %mul, ptr %uglygep77, align 8, !tbaa !6
    %uglygep82 = getelementptr i8, ptr %lsr.iv76, i64 -168
    %4 = load double, ptr %uglygep82, align 8, !tbaa !6
    %mul15 = fmul fast double %4, %3
    store double %mul15, ptr %uglygep81, align 8, !tbaa !6
    %uglygep83 = getelementptr i8, ptr %lsr.iv76, i64 -160
    %5 = load double, ptr %uglygep83, align 8, !tbaa !6
    %mul25 = fmul fast double %5, %4
    store double %mul25, ptr %uglygep82, align 8, !tbaa !6
    %uglygep84 = getelementptr i8, ptr %lsr.iv76, i64 -152
    %6 = load double, ptr %uglygep84, align 8, !tbaa !6
    %mul35 = fmul fast double %6, %5
    store double %mul35, ptr %uglygep83, align 8, !tbaa !6
    %uglygep80 = getelementptr i8, ptr %lsr.iv76, i64 -144
    %7 = load double, ptr %uglygep80, align 8, !tbaa !6
    %mul45 = fmul fast double %7, %6
    store double %mul45, ptr %uglygep84, align 8, !tbaa !6
    %uglygep85 = getelementptr i8, ptr %lsr.iv76, i64 -136
    %8 = load double, ptr %uglygep85, align 8, !tbaa !6
    %uglygep79 = getelementptr i8, ptr %lsr.iv76, i64 -144
    %mul.1 = fmul fast double %7, %8
    store double %mul.1, ptr %uglygep79, align 8, !tbaa !6
    %uglygep86 = getelementptr i8, ptr %lsr.iv76, i64 -128
    %9 = load double, ptr %uglygep86, align 8, !tbaa !6
    %mul15.1 = fmul fast double %9, %8
    store double %mul15.1, ptr %uglygep85, align 8, !tbaa !6
    %uglygep87 = getelementptr i8, ptr %lsr.iv76, i64 -120
    %10 = load double, ptr %uglygep87, align 8, !tbaa !6
    %mul25.1 = fmul fast double %10, %9
    store double %mul25.1, ptr %uglygep86, align 8, !tbaa !6
    %uglygep88 = getelementptr i8, ptr %lsr.iv76, i64 -112
    %11 = load double, ptr %uglygep88, align 8, !tbaa !6
    %mul35.1 = fmul fast double %11, %10
    store double %mul35.1, ptr %uglygep87, align 8, !tbaa !6
    %uglygep90 = getelementptr i8, ptr %lsr.iv76, i64 -104
    %12 = load double, ptr %uglygep90, align 8, !tbaa !6
    %mul45.1 = fmul fast double %12, %11
    store double %mul45.1, ptr %uglygep88, align 8, !tbaa !6
    %uglygep91 = getelementptr i8, ptr %lsr.iv76, i64 -96
    %13 = load double, ptr %uglygep91, align 8, !tbaa !6
    %uglygep89 = getelementptr i8, ptr %lsr.iv76, i64 -104
    %mul.2 = fmul fast double %12, %13
    store double %mul.2, ptr %uglygep89, align 8, !tbaa !6
    %uglygep92 = getelementptr i8, ptr %lsr.iv76, i64 -88
    %14 = load double, ptr %uglygep92, align 8, !tbaa !6
    %mul15.2 = fmul fast double %14, %13
    store double %mul15.2, ptr %uglygep91, align 8, !tbaa !6
    %uglygep93 = getelementptr i8, ptr %lsr.iv76, i64 -80
    %15 = load double, ptr %uglygep93, align 8, !tbaa !6
    %mul25.2 = fmul fast double %15, %14
    store double %mul25.2, ptr %uglygep92, align 8, !tbaa !6
    %uglygep94 = getelementptr i8, ptr %lsr.iv76, i64 -72
    %16 = load double, ptr %uglygep94, align 8, !tbaa !6
    %mul35.2 = fmul fast double %16, %15
    store double %mul35.2, ptr %uglygep93, align 8, !tbaa !6
    %uglygep96 = getelementptr i8, ptr %lsr.iv76, i64 -64
    %17 = load double, ptr %uglygep96, align 8, !tbaa !6
    %mul45.2 = fmul fast double %17, %16
    store double %mul45.2, ptr %uglygep94, align 8, !tbaa !6
    %uglygep97 = getelementptr i8, ptr %lsr.iv76, i64 -56
    %18 = load double, ptr %uglygep97, align 8, !tbaa !6
    %uglygep95 = getelementptr i8, ptr %lsr.iv76, i64 -64
    %mul.3 = fmul fast double %17, %18
    store double %mul.3, ptr %uglygep95, align 8, !tbaa !6
    %uglygep98 = getelementptr i8, ptr %lsr.iv76, i64 -48
    %19 = load double, ptr %uglygep98, align 8, !tbaa !6
    %mul15.3 = fmul fast double %19, %18
    store double %mul15.3, ptr %uglygep97, align 8, !tbaa !6
    %uglygep99 = getelementptr i8, ptr %lsr.iv76, i64 -40
    %20 = load double, ptr %uglygep99, align 8, !tbaa !6
    %mul25.3 = fmul fast double %20, %19
    store double %mul25.3, ptr %uglygep98, align 8, !tbaa !6
    %uglygep100 = getelementptr i8, ptr %lsr.iv76, i64 -32
    %21 = load double, ptr %uglygep100, align 8, !tbaa !6
    %mul35.3 = fmul fast double %21, %20
    store double %mul35.3, ptr %uglygep99, align 8, !tbaa !6
    %uglygep102 = getelementptr i8, ptr %lsr.iv76, i64 -24
    %22 = load double, ptr %uglygep102, align 8, !tbaa !6
    %mul45.3 = fmul fast double %22, %21
    store double %mul45.3, ptr %uglygep100, align 8, !tbaa !6
    %uglygep103 = getelementptr i8, ptr %lsr.iv76, i64 -16
    %23 = load double, ptr %uglygep103, align 8, !tbaa !6
    %uglygep101 = getelementptr i8, ptr %lsr.iv76, i64 -24
    %mul.4 = fmul fast double %22, %23
    store double %mul.4, ptr %uglygep101, align 8, !tbaa !6
    %uglygep104 = getelementptr i8, ptr %lsr.iv76, i64 -8
    %24 = load double, ptr %uglygep104, align 8, !tbaa !6
    %mul15.4 = fmul fast double %24, %23
    store double %mul15.4, ptr %uglygep103, align 8, !tbaa !6
    %25 = load double, ptr %lsr.iv76, align 8, !tbaa !6
    %mul25.4 = fmul fast double %25, %24
    store double %mul25.4, ptr %uglygep104, align 8, !tbaa !6
    %uglygep106 = getelementptr i8, ptr %lsr.iv76, i64 8
    %26 = load double, ptr %uglygep106, align 8, !tbaa !6
    %mul35.4 = fmul fast double %26, %25
    store double %mul35.4, ptr %lsr.iv76, align 8, !tbaa !6
    %uglygep108 = getelementptr i8, ptr %lsr.iv76, i64 16
    %27 = load double, ptr %uglygep108, align 8, !tbaa !6
    %mul45.4 = fmul fast double %27, %26
    store double %mul45.4, ptr %uglygep106, align 8, !tbaa !6
    %uglygep109 = getelementptr i8, ptr %lsr.iv76, i64 24
    %28 = load double, ptr %uglygep109, align 8, !tbaa !6
    %uglygep107 = getelementptr i8, ptr %lsr.iv76, i64 16
    %mul.5 = fmul fast double %27, %28
    store double %mul.5, ptr %uglygep107, align 8, !tbaa !6
    %uglygep110 = getelementptr i8, ptr %lsr.iv76, i64 32
    %29 = load double, ptr %uglygep110, align 8, !tbaa !6
    %mul15.5 = fmul fast double %29, %28
    store double %mul15.5, ptr %uglygep109, align 8, !tbaa !6
    %uglygep111 = getelementptr i8, ptr %lsr.iv76, i64 40
    %30 = load double, ptr %uglygep111, align 8, !tbaa !6
    %mul25.5 = fmul fast double %30, %29
    store double %mul25.5, ptr %uglygep110, align 8, !tbaa !6
    %uglygep112 = getelementptr i8, ptr %lsr.iv76, i64 48
    %31 = load double, ptr %uglygep112, align 8, !tbaa !6
    %mul35.5 = fmul fast double %31, %30
    store double %mul35.5, ptr %uglygep111, align 8, !tbaa !6
    %uglygep114 = getelementptr i8, ptr %lsr.iv76, i64 56
    %32 = load double, ptr %uglygep114, align 8, !tbaa !6
    %mul45.5 = fmul fast double %32, %31
    store double %mul45.5, ptr %uglygep112, align 8, !tbaa !6
    %uglygep115 = getelementptr i8, ptr %lsr.iv76, i64 64
    %33 = load double, ptr %uglygep115, align 8, !tbaa !6
    %uglygep113 = getelementptr i8, ptr %lsr.iv76, i64 56
    %mul.6 = fmul fast double %32, %33
    store double %mul.6, ptr %uglygep113, align 8, !tbaa !6
    %uglygep116 = getelementptr i8, ptr %lsr.iv76, i64 72
    %34 = load double, ptr %uglygep116, align 8, !tbaa !6
    %mul15.6 = fmul fast double %34, %33
    store double %mul15.6, ptr %uglygep115, align 8, !tbaa !6
    %uglygep117 = getelementptr i8, ptr %lsr.iv76, i64 80
    %35 = load double, ptr %uglygep117, align 8, !tbaa !6
    %mul25.6 = fmul fast double %35, %34
    store double %mul25.6, ptr %uglygep116, align 8, !tbaa !6
    %uglygep118 = getelementptr i8, ptr %lsr.iv76, i64 88
    %36 = load double, ptr %uglygep118, align 8, !tbaa !6
    %mul35.6 = fmul fast double %36, %35
    store double %mul35.6, ptr %uglygep117, align 8, !tbaa !6
    %uglygep120 = getelementptr i8, ptr %lsr.iv76, i64 96
    %37 = load double, ptr %uglygep120, align 8, !tbaa !6
    %mul45.6 = fmul fast double %37, %36
    store double %mul45.6, ptr %uglygep118, align 8, !tbaa !6
    %uglygep121 = getelementptr i8, ptr %lsr.iv76, i64 104
    %38 = load double, ptr %uglygep121, align 8, !tbaa !6
    %uglygep119 = getelementptr i8, ptr %lsr.iv76, i64 96
    %mul.7 = fmul fast double %37, %38
    store double %mul.7, ptr %uglygep119, align 8, !tbaa !6
    %uglygep122 = getelementptr i8, ptr %lsr.iv76, i64 112
    %39 = load double, ptr %uglygep122, align 8, !tbaa !6
    %mul15.7 = fmul fast double %39, %38
    store double %mul15.7, ptr %uglygep121, align 8, !tbaa !6
    %uglygep123 = getelementptr i8, ptr %lsr.iv76, i64 120
    %40 = load double, ptr %uglygep123, align 8, !tbaa !6
    %mul25.7 = fmul fast double %40, %39
    store double %mul25.7, ptr %uglygep122, align 8, !tbaa !6
    %uglygep124 = getelementptr i8, ptr %lsr.iv76, i64 128
    %41 = load double, ptr %uglygep124, align 8, !tbaa !6
    %mul35.7 = fmul fast double %41, %40
    store double %mul35.7, ptr %uglygep123, align 8, !tbaa !6
    %uglygep126 = getelementptr i8, ptr %lsr.iv76, i64 136
    %42 = load double, ptr %uglygep126, align 8, !tbaa !6
    %mul45.7 = fmul fast double %42, %41
    store double %mul45.7, ptr %uglygep124, align 8, !tbaa !6
    %uglygep127 = getelementptr i8, ptr %lsr.iv76, i64 144
    %43 = load double, ptr %uglygep127, align 8, !tbaa !6
    %uglygep125 = getelementptr i8, ptr %lsr.iv76, i64 136
    %mul.8 = fmul fast double %42, %43
    store double %mul.8, ptr %uglygep125, align 8, !tbaa !6
    %uglygep128 = getelementptr i8, ptr %lsr.iv76, i64 152
    %44 = load double, ptr %uglygep128, align 8, !tbaa !6
    %mul15.8 = fmul fast double %44, %43
    store double %mul15.8, ptr %uglygep127, align 8, !tbaa !6
    %uglygep129 = getelementptr i8, ptr %lsr.iv76, i64 160
    %45 = load double, ptr %uglygep129, align 8, !tbaa !6
    %mul25.8 = fmul fast double %45, %44
    store double %mul25.8, ptr %uglygep128, align 8, !tbaa !6
    %uglygep105 = getelementptr i8, ptr %lsr.iv76, i64 168
    %46 = load double, ptr %uglygep105, align 8, !tbaa !6
    %mul35.8 = fmul fast double %46, %45
    store double %mul35.8, ptr %uglygep129, align 8, !tbaa !6
    %uglygep78 = getelementptr i8, ptr %lsr.iv76, i64 176
    %47 = load double, ptr %uglygep78, align 8, !tbaa !6
    %mul45.8 = fmul fast double %47, %46
    store double %mul45.8, ptr %uglygep105, align 8, !tbaa !6
    %uglygep = getelementptr i8, ptr %lsr.iv76, i64 360
    %48 = call i64 @llvm.loop.decrement.reg.i64(i64 %2, i64 1)
    %49 = icmp ne i64 %48, 0
    br i1 %49, label %for.body4, label %for.cond.cleanup3, !llvm.loop !12
  }
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.start.loop.iterations.i64(i64) #1
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.loop.decrement.reg.i64(i64, i64) #1
  
  attributes #0 = { nofree norecurse nosync nounwind memory(readwrite, argmem: none, inaccessiblemem: none) uwtable vscale_range(1,16) "approx-func-fp-math"="true" "frame-pointer"="non-leaf" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+crypto,+fp-armv8,+fullfp16,+lse,+neon,+outline-atomics,+ras,+rdm,+sha2,+sve,+v8.1a,+v8.2a,+v8a,-fmv" "unsafe-fp-math"="true" }
  attributes #1 = { nocallback noduplicate nofree nosync nounwind willreturn }
  
  !llvm.module.flags = !{!0, !1, !2, !3, !4}
  !llvm.ident = !{!5}
  
  !0 = !{i32 1, !"wchar_size", i32 4}
  !1 = !{i32 8, !"PIC Level", i32 2}
  !2 = !{i32 7, !"PIE Level", i32 2}
  !3 = !{i32 7, !"uwtable", i32 2}
  !4 = !{i32 7, !"frame-pointer", i32 1}
  !5 = !{!"clang version 16.0.6 ()"}
  !6 = !{!7, !7, i64 0}
  !7 = !{!"double", !8, i64 0}
  !8 = !{!"omnipotent char", !9, i64 0}
  !9 = !{!"Simple C/C++ TBAA"}
  !10 = distinct !{!10, !11}
  !11 = !{!"llvm.loop.mustprogress"}
  !12 = distinct !{!12, !11, !13}
  !13 = !{!"llvm.loop.pipeline.initiationinterval", i32 111}

...
---
name:            s
alignment:       8
exposesReturnsTwice: false
legalized:       false
regBankSelected: false
selected:        false
failedISel:      false
tracksRegLiveness: true
hasWinCFI:       false
callsEHReturn:   false
callsUnwindInit: false
hasEHCatchret:   false
hasEHScopes:     false
hasEHFunclets:   false
debugInstrRef:   false
failsVerification: false
tracksDebugUserValues: false
registers:
  - { id: 0, class: gpr32sp, preferred-register: '' }
  - { id: 1, class: fpr64, preferred-register: '' }
  - { id: 2, class: gpr64all, preferred-register: '' }
  - { id: 3, class: gpr32all, preferred-register: '' }
  - { id: 4, class: gpr64sp, preferred-register: '' }
  - { id: 5, class: fpr64, preferred-register: '' }
  - { id: 6, class: gpr64sp, preferred-register: '' }
  - { id: 7, class: fpr64, preferred-register: '' }
  - { id: 8, class: gpr64all, preferred-register: '' }
  - { id: 9, class: gpr64all, preferred-register: '' }
  - { id: 10, class: gpr32all, preferred-register: '' }
  - { id: 11, class: gpr32all, preferred-register: '' }
  - { id: 12, class: gpr64all, preferred-register: '' }
  - { id: 13, class: gpr64common, preferred-register: '' }
  - { id: 14, class: gpr64sp, preferred-register: '' }
  - { id: 15, class: gpr32, preferred-register: '' }
  - { id: 16, class: fpr64, preferred-register: '' }
  - { id: 17, class: fpr64, preferred-register: '' }
  - { id: 18, class: fpr64, preferred-register: '' }
  - { id: 19, class: fpr64, preferred-register: '' }
  - { id: 20, class: fpr64, preferred-register: '' }
  - { id: 21, class: fpr64, preferred-register: '' }
  - { id: 22, class: fpr64, preferred-register: '' }
  - { id: 23, class: fpr64, preferred-register: '' }
  - { id: 24, class: fpr64, preferred-register: '' }
  - { id: 25, class: fpr64, preferred-register: '' }
  - { id: 26, class: fpr64, preferred-register: '' }
  - { id: 27, class: fpr64, preferred-register: '' }
  - { id: 28, class: fpr64, preferred-register: '' }
  - { id: 29, class: fpr64, preferred-register: '' }
  - { id: 30, class: fpr64, preferred-register: '' }
  - { id: 31, class: fpr64, preferred-register: '' }
  - { id: 32, class: fpr64, preferred-register: '' }
  - { id: 33, class: fpr64, preferred-register: '' }
  - { id: 34, class: fpr64, preferred-register: '' }
  - { id: 35, class: fpr64, preferred-register: '' }
  - { id: 36, class: fpr64, preferred-register: '' }
  - { id: 37, class: fpr64, preferred-register: '' }
  - { id: 38, class: fpr64, preferred-register: '' }
  - { id: 39, class: fpr64, preferred-register: '' }
  - { id: 40, class: fpr64, preferred-register: '' }
  - { id: 41, class: fpr64, preferred-register: '' }
  - { id: 42, class: fpr64, preferred-register: '' }
  - { id: 43, class: fpr64, preferred-register: '' }
  - { id: 44, class: fpr64, preferred-register: '' }
  - { id: 45, class: fpr64, preferred-register: '' }
  - { id: 46, class: fpr64, preferred-register: '' }
  - { id: 47, class: fpr64, preferred-register: '' }
  - { id: 48, class: fpr64, preferred-register: '' }
  - { id: 49, class: fpr64, preferred-register: '' }
  - { id: 50, class: fpr64, preferred-register: '' }
  - { id: 51, class: fpr64, preferred-register: '' }
  - { id: 52, class: fpr64, preferred-register: '' }
  - { id: 53, class: fpr64, preferred-register: '' }
  - { id: 54, class: fpr64, preferred-register: '' }
  - { id: 55, class: fpr64, preferred-register: '' }
  - { id: 56, class: fpr64, preferred-register: '' }
  - { id: 57, class: fpr64, preferred-register: '' }
  - { id: 58, class: fpr64, preferred-register: '' }
  - { id: 59, class: fpr64, preferred-register: '' }
  - { id: 60, class: fpr64, preferred-register: '' }
  - { id: 61, class: fpr64, preferred-register: '' }
  - { id: 62, class: fpr64, preferred-register: '' }
  - { id: 63, class: fpr64, preferred-register: '' }
  - { id: 64, class: fpr64, preferred-register: '' }
  - { id: 65, class: fpr64, preferred-register: '' }
  - { id: 66, class: fpr64, preferred-register: '' }
  - { id: 67, class: fpr64, preferred-register: '' }
  - { id: 68, class: fpr64, preferred-register: '' }
  - { id: 69, class: fpr64, preferred-register: '' }
  - { id: 70, class: fpr64, preferred-register: '' }
  - { id: 71, class: fpr64, preferred-register: '' }
  - { id: 72, class: fpr64, preferred-register: '' }
  - { id: 73, class: fpr64, preferred-register: '' }
  - { id: 74, class: fpr64, preferred-register: '' }
  - { id: 75, class: fpr64, preferred-register: '' }
  - { id: 76, class: fpr64, preferred-register: '' }
  - { id: 77, class: fpr64, preferred-register: '' }
  - { id: 78, class: fpr64, preferred-register: '' }
  - { id: 79, class: fpr64, preferred-register: '' }
  - { id: 80, class: fpr64, preferred-register: '' }
  - { id: 81, class: fpr64, preferred-register: '' }
  - { id: 82, class: fpr64, preferred-register: '' }
  - { id: 83, class: fpr64, preferred-register: '' }
  - { id: 84, class: fpr64, preferred-register: '' }
  - { id: 85, class: fpr64, preferred-register: '' }
  - { id: 86, class: fpr64, preferred-register: '' }
  - { id: 87, class: fpr64, preferred-register: '' }
  - { id: 88, class: fpr64, preferred-register: '' }
  - { id: 89, class: fpr64, preferred-register: '' }
  - { id: 90, class: fpr64, preferred-register: '' }
  - { id: 91, class: fpr64, preferred-register: '' }
  - { id: 92, class: fpr64, preferred-register: '' }
  - { id: 93, class: fpr64, preferred-register: '' }
  - { id: 94, class: fpr64, preferred-register: '' }
  - { id: 95, class: fpr64, preferred-register: '' }
  - { id: 96, class: fpr64, preferred-register: '' }
  - { id: 97, class: fpr64, preferred-register: '' }
  - { id: 98, class: fpr64, preferred-register: '' }
  - { id: 99, class: fpr64, preferred-register: '' }
  - { id: 100, class: fpr64, preferred-register: '' }
  - { id: 101, class: fpr64, preferred-register: '' }
  - { id: 102, class: fpr64, preferred-register: '' }
  - { id: 103, class: fpr64, preferred-register: '' }
  - { id: 104, class: fpr64, preferred-register: '' }
  - { id: 105, class: gpr64sp, preferred-register: '' }
  - { id: 106, class: gpr64, preferred-register: '' }
  - { id: 107, class: gpr32common, preferred-register: '' }
  - { id: 108, class: gpr32, preferred-register: '' }
  - { id: 109, class: gpr32, preferred-register: '' }
liveins:         []
frameInfo:
  isFrameAddressTaken: false
  isReturnAddressTaken: false
  hasStackMap:     false
  hasPatchPoint:   false
  stackSize:       0
  offsetAdjustment: 0
  maxAlignment:    1
  adjustsStack:    false
  hasCalls:        false
  stackProtector:  ''
  functionContext: ''
  maxCallFrameSize: 0
  cvBytesOfCalleeSavedRegisters: 0
  hasOpaqueSPAdjustment: false
  hasVAStart:      false
  hasMustTailInVarArgFunc: false
  hasTailCall:     false
  localFrameSize:  0
  savePoint:       ''
  restorePoint:    ''
fixedStack:      []
stack:           []
callSites:       []
debugValueSubstitutions: []
constants:       []
machineFunctionInfo: {}
body:             |
  bb.0.entry:
    successors: %bb.1(0x80000000)
  
    %11:gpr32all = COPY $wzr
    %10:gpr32all = COPY %11
    %13:gpr64common = LOADgot target-flags(aarch64-got) @a
    %15:gpr32 = MOVi32imm 711
    %108:gpr32 = MOVi32imm 1000000
  
  bb.1.for.cond1.preheader:
    successors: %bb.4(0x80000000)
  
    %0:gpr32sp = PHI %10, %bb.0, %3, %bb.3
    early-clobber %14:gpr64sp, %1:fpr64 = LDRDpost %13, 184 :: (load (s64) from @a, align 64, !tbaa !6)
    %12:gpr64all = COPY %14
    %2:gpr64all = SUBREG_TO_REG 0, %15, %subreg.sub_32
    B %bb.4
  
  bb.2.for.cond.cleanup:
    RET_ReallyLR
  
  bb.3.for.cond.cleanup3:
    successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  
    %107:gpr32common = nuw nsw ADDWri %0, 1, 0
    %3:gpr32all = COPY %107
    dead $wzr = SUBSWrr %107, %108, implicit-def $nzcv
    Bcc 0, %bb.2, implicit $nzcv
    B %bb.1
  
  bb.4.for.body4:
    successors: %bb.4(0x7c000000), %bb.3(0x04000000)
  
    %4:gpr64sp = PHI %12, %bb.1, %8, %bb.4
    %5:fpr64 = PHI %1, %bb.1, %7, %bb.4
    %6:gpr64sp = PHI %2, %bb.1, %9, %bb.4
    %16:fpr64 = LDURDi %4, -176 :: (load (s64) from %ir.uglygep81, !tbaa !6)
    %17:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %5, %16, implicit $fpcr
    STURDi killed %17, %4, -184 :: (store (s64) into %ir.uglygep77, !tbaa !6)
    %18:fpr64 = LDURDi %4, -168 :: (load (s64) from %ir.uglygep82, !tbaa !6)
    %19:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %18, %16, implicit $fpcr
    STURDi killed %19, %4, -176 :: (store (s64) into %ir.uglygep81, !tbaa !6)
    %20:fpr64 = LDURDi %4, -160 :: (load (s64) from %ir.uglygep83, !tbaa !6)
    %21:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %20, %18, implicit $fpcr
    STURDi killed %21, %4, -168 :: (store (s64) into %ir.uglygep82, !tbaa !6)
    %22:fpr64 = LDURDi %4, -152 :: (load (s64) from %ir.uglygep84, !tbaa !6)
    %23:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %22, %20, implicit $fpcr
    STURDi killed %23, %4, -160 :: (store (s64) into %ir.uglygep83, !tbaa !6)
    %24:fpr64 = LDURDi %4, -144 :: (load (s64) from %ir.uglygep80, !tbaa !6)
    %25:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %24, %22, implicit $fpcr
    STURDi killed %25, %4, -152 :: (store (s64) into %ir.uglygep84, !tbaa !6)
    %26:fpr64 = LDURDi %4, -136 :: (load (s64) from %ir.uglygep85, !tbaa !6)
    %27:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %24, %26, implicit $fpcr
    STURDi killed %27, %4, -144 :: (store (s64) into %ir.uglygep79, !tbaa !6)
    %28:fpr64 = LDURDi %4, -128 :: (load (s64) from %ir.uglygep86, !tbaa !6)
    %29:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %28, %26, implicit $fpcr
    STURDi killed %29, %4, -136 :: (store (s64) into %ir.uglygep85, !tbaa !6)
    %30:fpr64 = LDURDi %4, -120 :: (load (s64) from %ir.uglygep87, !tbaa !6)
    %31:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %30, %28, implicit $fpcr
    STURDi killed %31, %4, -128 :: (store (s64) into %ir.uglygep86, !tbaa !6)
    %32:fpr64 = LDURDi %4, -112 :: (load (s64) from %ir.uglygep88, !tbaa !6)
    %33:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %32, %30, implicit $fpcr
    STURDi killed %33, %4, -120 :: (store (s64) into %ir.uglygep87, !tbaa !6)
    %34:fpr64 = LDURDi %4, -104 :: (load (s64) from %ir.uglygep90, !tbaa !6)
    %35:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %34, %32, implicit $fpcr
    STURDi killed %35, %4, -112 :: (store (s64) into %ir.uglygep88, !tbaa !6)
    %36:fpr64 = LDURDi %4, -96 :: (load (s64) from %ir.uglygep91, !tbaa !6)
    %37:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %34, %36, implicit $fpcr
    STURDi killed %37, %4, -104 :: (store (s64) into %ir.uglygep89, !tbaa !6)
    %38:fpr64 = LDURDi %4, -88 :: (load (s64) from %ir.uglygep92, !tbaa !6)
    %39:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %38, %36, implicit $fpcr
    STURDi killed %39, %4, -96 :: (store (s64) into %ir.uglygep91, !tbaa !6)
    %40:fpr64 = LDURDi %4, -80 :: (load (s64) from %ir.uglygep93, !tbaa !6)
    %41:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %40, %38, implicit $fpcr
    STURDi killed %41, %4, -88 :: (store (s64) into %ir.uglygep92, !tbaa !6)
    %42:fpr64 = LDURDi %4, -72 :: (load (s64) from %ir.uglygep94, !tbaa !6)
    %43:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %42, %40, implicit $fpcr
    STURDi killed %43, %4, -80 :: (store (s64) into %ir.uglygep93, !tbaa !6)
    %44:fpr64 = LDURDi %4, -64 :: (load (s64) from %ir.uglygep96, !tbaa !6)
    %45:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %44, %42, implicit $fpcr
    STURDi killed %45, %4, -72 :: (store (s64) into %ir.uglygep94, !tbaa !6)
    %46:fpr64 = LDURDi %4, -56 :: (load (s64) from %ir.uglygep97, !tbaa !6)
    %47:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %44, %46, implicit $fpcr
    STURDi killed %47, %4, -64 :: (store (s64) into %ir.uglygep95, !tbaa !6)
    %48:fpr64 = LDURDi %4, -48 :: (load (s64) from %ir.uglygep98, !tbaa !6)
    %49:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %48, %46, implicit $fpcr
    STURDi killed %49, %4, -56 :: (store (s64) into %ir.uglygep97, !tbaa !6)
    %50:fpr64 = LDURDi %4, -40 :: (load (s64) from %ir.uglygep99, !tbaa !6)
    %51:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %50, %48, implicit $fpcr
    STURDi killed %51, %4, -48 :: (store (s64) into %ir.uglygep98, !tbaa !6)
    %52:fpr64 = LDURDi %4, -32 :: (load (s64) from %ir.uglygep100, !tbaa !6)
    %53:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %52, %50, implicit $fpcr
    STURDi killed %53, %4, -40 :: (store (s64) into %ir.uglygep99, !tbaa !6)
    %54:fpr64 = LDURDi %4, -24 :: (load (s64) from %ir.uglygep102, !tbaa !6)
    %55:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %54, %52, implicit $fpcr
    STURDi killed %55, %4, -32 :: (store (s64) into %ir.uglygep100, !tbaa !6)
    %56:fpr64 = LDURDi %4, -16 :: (load (s64) from %ir.uglygep103, !tbaa !6)
    %57:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %54, %56, implicit $fpcr
    STURDi killed %57, %4, -24 :: (store (s64) into %ir.uglygep101, !tbaa !6)
    %58:fpr64 = LDURDi %4, -8 :: (load (s64) from %ir.uglygep104, !tbaa !6)
    %59:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %58, %56, implicit $fpcr
    STURDi killed %59, %4, -16 :: (store (s64) into %ir.uglygep103, !tbaa !6)
    %60:fpr64 = LDRDui %4, 0 :: (load (s64) from %ir.lsr.iv76, !tbaa !6)
    %61:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %60, %58, implicit $fpcr
    STURDi killed %61, %4, -8 :: (store (s64) into %ir.uglygep104, !tbaa !6)
    %62:fpr64 = LDRDui %4, 1 :: (load (s64) from %ir.uglygep106, !tbaa !6)
    %63:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %62, %60, implicit $fpcr
    STRDui killed %63, %4, 0 :: (store (s64) into %ir.lsr.iv76, !tbaa !6)
    %64:fpr64 = LDRDui %4, 2 :: (load (s64) from %ir.uglygep108, !tbaa !6)
    %65:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %64, %62, implicit $fpcr
    STRDui killed %65, %4, 1 :: (store (s64) into %ir.uglygep106, !tbaa !6)
    %66:fpr64 = LDRDui %4, 3 :: (load (s64) from %ir.uglygep109, !tbaa !6)
    %67:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %64, %66, implicit $fpcr
    STRDui killed %67, %4, 2 :: (store (s64) into %ir.uglygep107, !tbaa !6)
    %68:fpr64 = LDRDui %4, 4 :: (load (s64) from %ir.uglygep110, !tbaa !6)
    %69:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %68, %66, implicit $fpcr
    STRDui killed %69, %4, 3 :: (store (s64) into %ir.uglygep109, !tbaa !6)
    %70:fpr64 = LDRDui %4, 5 :: (load (s64) from %ir.uglygep111, !tbaa !6)
    %71:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %70, %68, implicit $fpcr
    STRDui killed %71, %4, 4 :: (store (s64) into %ir.uglygep110, !tbaa !6)
    %72:fpr64 = LDRDui %4, 6 :: (load (s64) from %ir.uglygep112, !tbaa !6)
    %73:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %72, %70, implicit $fpcr
    STRDui killed %73, %4, 5 :: (store (s64) into %ir.uglygep111, !tbaa !6)
    %74:fpr64 = LDRDui %4, 7 :: (load (s64) from %ir.uglygep114, !tbaa !6)
    %75:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %74, %72, implicit $fpcr
    STRDui killed %75, %4, 6 :: (store (s64) into %ir.uglygep112, !tbaa !6)
    %76:fpr64 = LDRDui %4, 8 :: (load (s64) from %ir.uglygep115, !tbaa !6)
    %77:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %74, %76, implicit $fpcr
    STRDui killed %77, %4, 7 :: (store (s64) into %ir.uglygep113, !tbaa !6)
    %78:fpr64 = LDRDui %4, 9 :: (load (s64) from %ir.uglygep116, !tbaa !6)
    %79:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %78, %76, implicit $fpcr
    STRDui killed %79, %4, 8 :: (store (s64) into %ir.uglygep115, !tbaa !6)
    %80:fpr64 = LDRDui %4, 10 :: (load (s64) from %ir.uglygep117, !tbaa !6)
    %81:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %80, %78, implicit $fpcr
    STRDui killed %81, %4, 9 :: (store (s64) into %ir.uglygep116, !tbaa !6)
    %82:fpr64 = LDRDui %4, 11 :: (load (s64) from %ir.uglygep118, !tbaa !6)
    %83:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %82, %80, implicit $fpcr
    STRDui killed %83, %4, 10 :: (store (s64) into %ir.uglygep117, !tbaa !6)
    %84:fpr64 = LDRDui %4, 12 :: (load (s64) from %ir.uglygep120, !tbaa !6)
    %85:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %84, %82, implicit $fpcr
    STRDui killed %85, %4, 11 :: (store (s64) into %ir.uglygep118, !tbaa !6)
    %86:fpr64 = LDRDui %4, 13 :: (load (s64) from %ir.uglygep121, !tbaa !6)
    %87:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %84, %86, implicit $fpcr
    STRDui killed %87, %4, 12 :: (store (s64) into %ir.uglygep119, !tbaa !6)
    %88:fpr64 = LDRDui %4, 14 :: (load (s64) from %ir.uglygep122, !tbaa !6)
    %89:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %88, %86, implicit $fpcr
    STRDui killed %89, %4, 13 :: (store (s64) into %ir.uglygep121, !tbaa !6)
    %90:fpr64 = LDRDui %4, 15 :: (load (s64) from %ir.uglygep123, !tbaa !6)
    %91:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %90, %88, implicit $fpcr
    STRDui killed %91, %4, 14 :: (store (s64) into %ir.uglygep122, !tbaa !6)
    %92:fpr64 = LDRDui %4, 16 :: (load (s64) from %ir.uglygep124, !tbaa !6)
    %93:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %92, %90, implicit $fpcr
    STRDui killed %93, %4, 15 :: (store (s64) into %ir.uglygep123, !tbaa !6)
    %94:fpr64 = LDRDui %4, 17 :: (load (s64) from %ir.uglygep126, !tbaa !6)
    %95:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %94, %92, implicit $fpcr
    STRDui killed %95, %4, 16 :: (store (s64) into %ir.uglygep124, !tbaa !6)
    %96:fpr64 = LDRDui %4, 18 :: (load (s64) from %ir.uglygep127, !tbaa !6)
    %97:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %94, %96, implicit $fpcr
    STRDui killed %97, %4, 17 :: (store (s64) into %ir.uglygep125, !tbaa !6)
    %98:fpr64 = LDRDui %4, 19 :: (load (s64) from %ir.uglygep128, !tbaa !6)
    %99:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %98, %96, implicit $fpcr
    STRDui killed %99, %4, 18 :: (store (s64) into %ir.uglygep127, !tbaa !6)
    %100:fpr64 = LDRDui %4, 20 :: (load (s64) from %ir.uglygep129, !tbaa !6)
    %101:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %100, %98, implicit $fpcr
    STRDui killed %101, %4, 19 :: (store (s64) into %ir.uglygep128, !tbaa !6)
    %102:fpr64 = LDRDui %4, 21 :: (load (s64) from %ir.uglygep105, !tbaa !6)
    %103:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %102, %100, implicit $fpcr
    STRDui killed %103, %4, 20 :: (store (s64) into %ir.uglygep129, !tbaa !6)
    %7:fpr64 = LDRDui %4, 22 :: (load (s64) from %ir.uglygep78, !tbaa !6)
    %104:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %7, %102, implicit $fpcr
    STRDui killed %104, %4, 21 :: (store (s64) into %ir.uglygep105, !tbaa !6)
    %105:gpr64sp = ADDXri %4, 360, 0
    %8:gpr64all = COPY %105
    %106:gpr64 = SUBSXri %6, 1, 0, implicit-def $nzcv
    %9:gpr64all = COPY %106
    Bcc 1, %bb.4, implicit $nzcv
    B %bb.3

...
