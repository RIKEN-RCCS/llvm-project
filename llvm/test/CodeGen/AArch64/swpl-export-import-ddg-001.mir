# RUN: echo dummy-data > %t.yaml
# RUN: llc -mcpu=a64fx -start-before=aarch64-swpipeliner -fswp -export-swpl-dep-mi=%t.yaml -o /dev/null %s
# RUN: FileCheck %s --input-file=%t.yaml

# CHECK-NOT: dummy-data
# CHECK: ---
# CHECK-NEXT: fname:           s
# CHECK-NEXT: loopid:          1
# CHECK-NEXT: deps:
# CHECK-NEXT:   - from:            { id: 0, mi: '%140:zpr = LD1D_IMM %98:ppr_3b, %138:gpr64sp, 0 :: (load unknown-size from %ir.lsr.iv, align 64, !tbaa !13)' }
# CHECK-NEXT:     to:              { id: 3, mi: 'ST1D_IMM killed %145:zpr, %143:ppr_3b, %137:gpr64sp, 0 :: (store unknown-size into %ir.lsr.iv122, align 8, !tbaa !13)' }
# CHECK-NEXT:     distance:        20

--- |
  ; ModuleID = '/home/dev/s.c'
  source_filename = "/home/dev/s.c"
  target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
  target triple = "aarch64-swpipeliner"
  
  %struct.args_t = type { %struct.timeval, %struct.timeval, ptr }
  %struct.timeval = type { i64, i64 }
  
  @__func__.s = private unnamed_addr constant [2 x i8] c"s\00", align 1
  @a = external dso_local global [32000 x double], align 64
  @b = external dso_local global [32000 x double], align 64
  @d = external dso_local global [32000 x double], align 64
  @c = external dso_local global [32000 x double], align 64
  @e = external dso_local global [32000 x double], align 64
  @aa = external dso_local global [256 x [256 x double]], align 64
  @bb = external dso_local global [256 x [256 x double]], align 64
  @cc = external dso_local global [256 x [256 x double]], align 64
  
  ; Function Attrs: nounwind uwtable vscale_range(4,4)
  define dso_local nofpclass(nan inf) double @s(ptr nocapture noundef %func_args) local_unnamed_addr #0 {
  entry:
    %arg_info = getelementptr inbounds %struct.args_t, ptr %func_args, i64 0, i32 2
    %0 = load ptr, ptr %arg_info, align 8, !tbaa !4
    %1 = load i32, ptr %0, align 4, !tbaa !11
    %call = tail call i32 @initialise_arrays(ptr noundef nonnull @__func__.s) #5
    %call1 = tail call i32 @gettimeofday(ptr noundef %func_args, ptr noundef null) #5
    %.fr = freeze i32 %1
    %cmp33 = icmp sgt i32 %.fr, 0
    br i1 %cmp33, label %vector.ph106.preheader, label %vector.ph.preheader
  
  vector.ph.preheader:                              ; preds = %entry
    br label %vector.ph
  
  vector.ph106.preheader:                           ; preds = %entry
    br label %vector.ph106
  
  vector.ph106:                                     ; preds = %vector.ph106.preheader, %for.cond.cleanup4.split.us.us
    %nl.087.us = phi i32 [ %inc58.us, %for.cond.cleanup4.split.us.us ], [ 0, %vector.ph106.preheader ]
    %2 = call i64 @llvm.start.loop.iterations.i64(i64 4000)
    br label %vector.body111
  
  vector.body111:                                   ; preds = %vector.body111, %vector.ph106
    %lsr.iv128 = phi ptr [ %scevgep129, %vector.body111 ], [ @c, %vector.ph106 ]
    %lsr.iv126 = phi ptr [ %scevgep127, %vector.body111 ], [ @d, %vector.ph106 ]
    %lsr.iv124 = phi ptr [ %scevgep125, %vector.body111 ], [ @e, %vector.ph106 ]
    %lsr.iv122 = phi ptr [ %scevgep123, %vector.body111 ], [ @b, %vector.ph106 ]
    %lsr.iv = phi ptr [ %scevgep, %vector.body111 ], [ @a, %vector.ph106 ]
    %3 = phi i64 [ %2, %vector.ph106 ], [ %14, %vector.body111 ]
    %wide.load113 = load <vscale x 2 x double>, ptr %lsr.iv, align 64, !tbaa !13
    %wide.load114 = load <vscale x 2 x double>, ptr %lsr.iv122, align 64, !tbaa !13
    %4 = fcmp fast ogt <vscale x 2 x double> %wide.load113, %wide.load114
    %wide.load115 = load <vscale x 2 x double>, ptr %lsr.iv124, align 64, !tbaa !13
    %5 = fmul fast <vscale x 2 x double> %wide.load115, %wide.load115
    %6 = fadd fast <vscale x 2 x double> %5, %wide.load113
    %7 = xor <vscale x 2 x i1> %4, shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer)
    tail call void @llvm.masked.store.nxv2f64.p0(<vscale x 2 x double> %6, ptr %lsr.iv122, i32 8, <vscale x 2 x i1> %7), !tbaa !13
    %wide.load116 = load <vscale x 2 x double>, ptr %lsr.iv126, align 64, !tbaa !13
    %8 = fmul fast <vscale x 2 x double> %wide.load116, %wide.load116
    %9 = fadd fast <vscale x 2 x double> %8, %wide.load113
    tail call void @llvm.masked.store.nxv2f64.p0(<vscale x 2 x double> %9, ptr %lsr.iv128, i32 8, <vscale x 2 x i1> %7), !tbaa !13
    %10 = fmul fast <vscale x 2 x double> %wide.load116, %wide.load114
    %11 = fadd fast <vscale x 2 x double> %10, %wide.load113
    tail call void @llvm.masked.store.nxv2f64.p0(<vscale x 2 x double> %11, ptr %lsr.iv, i32 8, <vscale x 2 x i1> %4), !tbaa !13
    %12 = fmul fast <vscale x 2 x double> %wide.load116, %wide.load116
    %wide.load118 = load <vscale x 2 x double>, ptr %lsr.iv128, align 64, !tbaa !13
    %13 = fadd fast <vscale x 2 x double> %wide.load118, %12
    tail call void @llvm.masked.store.nxv2f64.p0(<vscale x 2 x double> %13, ptr %lsr.iv128, i32 8, <vscale x 2 x i1> %4), !tbaa !13
    %scevgep = getelementptr i8, ptr %lsr.iv, i64 64
    %scevgep123 = getelementptr i8, ptr %lsr.iv122, i64 64
    %scevgep125 = getelementptr i8, ptr %lsr.iv124, i64 64
    %scevgep127 = getelementptr i8, ptr %lsr.iv126, i64 64
    %scevgep129 = getelementptr i8, ptr %lsr.iv128, i64 64
    %14 = call i64 @llvm.loop.decrement.reg.i64(i64 %3, i64 1)
    %15 = icmp ne i64 %14, 0
    br i1 %15, label %vector.body111, label %for.cond.cleanup4.split.us.us, !llvm.loop !15
  
  for.cond.cleanup4.split.us.us:                    ; preds = %vector.body111
    %call56.us = tail call i32 @dummy(ptr noundef nonnull @a, ptr noundef nonnull @b, ptr noundef nonnull @c, ptr noundef nonnull @d, ptr noundef nonnull @e, ptr noundef nonnull @aa, ptr noundef nonnull @bb, ptr noundef nonnull @cc, double noundef nofpclass(nan inf) 0.000000e+00) #5
    %inc58.us = add nuw nsw i32 %nl.087.us, 1
    %exitcond95.not = icmp eq i32 %inc58.us, 50000
    br i1 %exitcond95.not, label %for.cond.cleanup, label %vector.ph106, !llvm.loop !20
  
  vector.ph:                                        ; preds = %vector.ph.preheader, %for.cond.cleanup4.split
    %nl.087 = phi i32 [ %inc58, %for.cond.cleanup4.split ], [ 0, %vector.ph.preheader ]
    %16 = call i64 @llvm.start.loop.iterations.i64(i64 4000)
    br label %vector.body
  
  vector.body:                                      ; preds = %vector.body, %vector.ph
    %lsr.iv139 = phi ptr [ %scevgep140, %vector.body ], [ @c, %vector.ph ]
    %lsr.iv137 = phi ptr [ %scevgep138, %vector.body ], [ @d, %vector.ph ]
    %lsr.iv135 = phi ptr [ %scevgep136, %vector.body ], [ @e, %vector.ph ]
    %lsr.iv133 = phi ptr [ %scevgep134, %vector.body ], [ @b, %vector.ph ]
    %lsr.iv131 = phi ptr [ %scevgep132, %vector.body ], [ @a, %vector.ph ]
    %17 = phi i64 [ %16, %vector.ph ], [ %26, %vector.body ]
    %wide.load = load <vscale x 2 x double>, ptr %lsr.iv131, align 64, !tbaa !13
    %wide.load99 = load <vscale x 2 x double>, ptr %lsr.iv133, align 64, !tbaa !13
    %18 = fcmp fast ogt <vscale x 2 x double> %wide.load, %wide.load99
    %wide.load100 = load <vscale x 2 x double>, ptr %lsr.iv135, align 64, !tbaa !13
    %19 = fmul fast <vscale x 2 x double> %wide.load100, %wide.load100
    %20 = fadd fast <vscale x 2 x double> %19, %wide.load
    %21 = xor <vscale x 2 x i1> %18, shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer)
    tail call void @llvm.masked.store.nxv2f64.p0(<vscale x 2 x double> %20, ptr %lsr.iv133, i32 8, <vscale x 2 x i1> %21), !tbaa !13
    %wide.load101 = load <vscale x 2 x double>, ptr %lsr.iv137, align 64, !tbaa !13
    %22 = fmul fast <vscale x 2 x double> %wide.load101, %wide.load99
    %23 = fadd fast <vscale x 2 x double> %22, %wide.load
    tail call void @llvm.masked.store.nxv2f64.p0(<vscale x 2 x double> %23, ptr %lsr.iv131, i32 8, <vscale x 2 x i1> %18), !tbaa !13
    %24 = fmul fast <vscale x 2 x double> %wide.load101, %wide.load101
    %predphi = select <vscale x 2 x i1> %18, <vscale x 2 x double> %24, <vscale x 2 x double> %19
    %wide.load102 = load <vscale x 2 x double>, ptr %lsr.iv139, align 64, !tbaa !13
    %25 = fadd fast <vscale x 2 x double> %wide.load102, %predphi
    store <vscale x 2 x double> %25, ptr %lsr.iv139, align 64, !tbaa !13
    %scevgep132 = getelementptr i8, ptr %lsr.iv131, i64 64
    %scevgep134 = getelementptr i8, ptr %lsr.iv133, i64 64
    %scevgep136 = getelementptr i8, ptr %lsr.iv135, i64 64
    %scevgep138 = getelementptr i8, ptr %lsr.iv137, i64 64
    %scevgep140 = getelementptr i8, ptr %lsr.iv139, i64 64
    %26 = call i64 @llvm.loop.decrement.reg.i64(i64 %17, i64 1)
    %27 = icmp ne i64 %26, 0
    br i1 %27, label %vector.body, label %for.cond.cleanup4.split, !llvm.loop !21
  
  for.cond.cleanup:                                 ; preds = %for.cond.cleanup4.split, %for.cond.cleanup4.split.us.us
    %t2 = getelementptr inbounds %struct.args_t, ptr %func_args, i64 0, i32 1
    %call60 = tail call i32 @gettimeofday(ptr noundef nonnull %t2, ptr noundef null) #5
    %call61 = tail call fast nofpclass(nan inf) double @calc_checksum(ptr noundef nonnull @__func__.s) #5
    ret double %call61
  
  for.cond.cleanup4.split:                          ; preds = %vector.body
    %call56 = tail call i32 @dummy(ptr noundef nonnull @a, ptr noundef nonnull @b, ptr noundef nonnull @c, ptr noundef nonnull @d, ptr noundef nonnull @e, ptr noundef nonnull @aa, ptr noundef nonnull @bb, ptr noundef nonnull @cc, double noundef nofpclass(nan inf) 0.000000e+00) #5
    %inc58 = add nuw nsw i32 %nl.087, 1
    %exitcond90.not = icmp eq i32 %inc58, 50000
    br i1 %exitcond90.not, label %for.cond.cleanup, label %vector.ph, !llvm.loop !20
  }
  
  declare dso_local i32 @initialise_arrays(ptr noundef) local_unnamed_addr #1
  
  ; Function Attrs: nofree nounwind
  declare dso_local noundef i32 @gettimeofday(ptr nocapture noundef, ptr nocapture noundef) local_unnamed_addr #2
  
  declare dso_local i32 @dummy(ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, double noundef nofpclass(nan inf)) local_unnamed_addr #1
  
  declare dso_local nofpclass(nan inf) double @calc_checksum(ptr noundef) local_unnamed_addr #1
  
  ; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: write)
  declare void @llvm.masked.store.nxv2f64.p0(<vscale x 2 x double>, ptr nocapture, i32 immarg, <vscale x 2 x i1>) #3
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.start.loop.iterations.i64(i64) #4
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.loop.decrement.reg.i64(i64, i64) #4
  
  attributes #0 = { nounwind uwtable vscale_range(4,4) "approx-func-fp-math"="true" "frame-pointer"="non-leaf" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+fp-armv8,+fullfp16,+lse,+neon,+ras,+rdm,+sha2,+sve,+v8.1a,+v8.2a,+v8a,-fmv" "unsafe-fp-math"="true" }
  attributes #1 = { "approx-func-fp-math"="true" "frame-pointer"="non-leaf" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+fp-armv8,+fullfp16,+lse,+neon,+ras,+rdm,+sha2,+sve,+v8.1a,+v8.2a,+v8a,-fmv" "unsafe-fp-math"="true" }
  attributes #2 = { nofree nounwind "approx-func-fp-math"="true" "frame-pointer"="non-leaf" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+fp-armv8,+fullfp16,+lse,+neon,+ras,+rdm,+sha2,+sve,+v8.1a,+v8.2a,+v8a,-fmv" "unsafe-fp-math"="true" }
  attributes #3 = { nocallback nofree nosync nounwind willreturn memory(argmem: write) }
  attributes #4 = { nocallback noduplicate nofree nosync nounwind willreturn }
  attributes #5 = { nounwind }
  
  !llvm.module.flags = !{!0, !1, !2}
  !llvm.ident = !{!3}
  
  !0 = !{i32 1, !"wchar_size", i32 4}
  !1 = !{i32 7, !"uwtable", i32 2}
  !2 = !{i32 7, !"frame-pointer", i32 1}
  !3 = !{!"clang version 17.0.3 ()"}
  !4 = !{!5, !10, i64 32}
  !5 = !{!"args_t", !6, i64 0, !6, i64 16, !10, i64 32}
  !6 = !{!"timeval", !7, i64 0, !7, i64 8}
  !7 = !{!"long", !8, i64 0}
  !8 = !{!"omnipotent char", !9, i64 0}
  !9 = !{!"Simple C/C++ TBAA"}
  !10 = !{!"any pointer", !8, i64 0}
  !11 = !{!12, !12, i64 0}
  !12 = !{!"int", !8, i64 0}
  !13 = !{!14, !14, i64 0}
  !14 = !{!"double", !8, i64 0}
  !15 = distinct !{!15, !16, !17, !18, !19}
  !16 = !{!"llvm.loop.mustprogress"}
  !17 = !{!"llvm.loop.unroll.disable"}
  !18 = !{!"llvm.loop.isvectorized", i32 1}
  !19 = !{!"llvm.loop.unroll.runtime.disable"}
  !20 = distinct !{!20, !16, !17}
  !21 = distinct !{!21, !16, !17, !18, !19}

...
---
name:            s
alignment:       8
exposesReturnsTwice: false
legalized:       false
regBankSelected: false
selected:        false
failedISel:      false
tracksRegLiveness: true
hasWinCFI:       false
callsEHReturn:   false
callsUnwindInit: false
hasEHCatchret:   false
hasEHScopes:     false
hasEHFunclets:   false
isOutlined:      false
debugInstrRef:   false
failsVerification: false
tracksDebugUserValues: false
registers:
  - { id: 0, class: gpr32sp, preferred-register: '' }
  - { id: 1, class: gpr64all, preferred-register: '' }
  - { id: 2, class: gpr64sp, preferred-register: '' }
  - { id: 3, class: gpr64sp, preferred-register: '' }
  - { id: 4, class: gpr64sp, preferred-register: '' }
  - { id: 5, class: gpr64sp, preferred-register: '' }
  - { id: 6, class: gpr64sp, preferred-register: '' }
  - { id: 7, class: gpr64sp, preferred-register: '' }
  - { id: 8, class: gpr64all, preferred-register: '' }
  - { id: 9, class: gpr64all, preferred-register: '' }
  - { id: 10, class: gpr64all, preferred-register: '' }
  - { id: 11, class: gpr64all, preferred-register: '' }
  - { id: 12, class: gpr64all, preferred-register: '' }
  - { id: 13, class: gpr64all, preferred-register: '' }
  - { id: 14, class: gpr32all, preferred-register: '' }
  - { id: 15, class: gpr32sp, preferred-register: '' }
  - { id: 16, class: gpr64all, preferred-register: '' }
  - { id: 17, class: gpr64sp, preferred-register: '' }
  - { id: 18, class: gpr64sp, preferred-register: '' }
  - { id: 19, class: gpr64sp, preferred-register: '' }
  - { id: 20, class: gpr64sp, preferred-register: '' }
  - { id: 21, class: gpr64sp, preferred-register: '' }
  - { id: 22, class: gpr64sp, preferred-register: '' }
  - { id: 23, class: gpr64all, preferred-register: '' }
  - { id: 24, class: gpr64all, preferred-register: '' }
  - { id: 25, class: gpr64all, preferred-register: '' }
  - { id: 26, class: gpr64all, preferred-register: '' }
  - { id: 27, class: gpr64all, preferred-register: '' }
  - { id: 28, class: gpr64all, preferred-register: '' }
  - { id: 29, class: gpr32all, preferred-register: '' }
  - { id: 30, class: gpr64common, preferred-register: '' }
  - { id: 31, class: gpr64common, preferred-register: '' }
  - { id: 32, class: gpr32common, preferred-register: '' }
  - { id: 33, class: gpr64common, preferred-register: '' }
  - { id: 34, class: gpr32all, preferred-register: '' }
  - { id: 35, class: gpr64all, preferred-register: '' }
  - { id: 36, class: gpr32all, preferred-register: '' }
  - { id: 37, class: gpr32, preferred-register: '' }
  - { id: 38, class: gpr32all, preferred-register: '' }
  - { id: 39, class: gpr32all, preferred-register: '' }
  - { id: 40, class: gpr64all, preferred-register: '' }
  - { id: 41, class: gpr64all, preferred-register: '' }
  - { id: 42, class: gpr64all, preferred-register: '' }
  - { id: 43, class: gpr64all, preferred-register: '' }
  - { id: 44, class: gpr64all, preferred-register: '' }
  - { id: 45, class: gpr64common, preferred-register: '' }
  - { id: 46, class: gpr64common, preferred-register: '' }
  - { id: 47, class: gpr64common, preferred-register: '' }
  - { id: 48, class: gpr64common, preferred-register: '' }
  - { id: 49, class: gpr64common, preferred-register: '' }
  - { id: 50, class: gpr32, preferred-register: '' }
  - { id: 51, class: ppr_3b, preferred-register: '' }
  - { id: 52, class: zpr, preferred-register: '' }
  - { id: 53, class: zpr, preferred-register: '' }
  - { id: 54, class: ppr_3b, preferred-register: '' }
  - { id: 55, class: ppr_3b, preferred-register: '' }
  - { id: 56, class: ppr_3b, preferred-register: '' }
  - { id: 57, class: zpr, preferred-register: '' }
  - { id: 58, class: zpr, preferred-register: '' }
  - { id: 59, class: zpr, preferred-register: '' }
  - { id: 60, class: zpr, preferred-register: '' }
  - { id: 61, class: zpr, preferred-register: '' }
  - { id: 62, class: zpr, preferred-register: '' }
  - { id: 63, class: zpr, preferred-register: '' }
  - { id: 64, class: zpr, preferred-register: '' }
  - { id: 65, class: zpr, preferred-register: '' }
  - { id: 66, class: gpr64sp, preferred-register: '' }
  - { id: 67, class: gpr64sp, preferred-register: '' }
  - { id: 68, class: gpr64sp, preferred-register: '' }
  - { id: 69, class: gpr64sp, preferred-register: '' }
  - { id: 70, class: gpr64sp, preferred-register: '' }
  - { id: 71, class: gpr64, preferred-register: '' }
  - { id: 72, class: gpr64common, preferred-register: '' }
  - { id: 73, class: gpr64common, preferred-register: '' }
  - { id: 74, class: gpr64common, preferred-register: '' }
  - { id: 75, class: gpr64common, preferred-register: '' }
  - { id: 76, class: gpr64common, preferred-register: '' }
  - { id: 77, class: gpr64common, preferred-register: '' }
  - { id: 78, class: gpr64common, preferred-register: '' }
  - { id: 79, class: gpr64common, preferred-register: '' }
  - { id: 80, class: fpr64, preferred-register: '' }
  - { id: 81, class: gpr32all, preferred-register: '' }
  - { id: 82, class: gpr32common, preferred-register: '' }
  - { id: 83, class: gpr32, preferred-register: '' }
  - { id: 84, class: gpr32, preferred-register: '' }
  - { id: 85, class: gpr32all, preferred-register: '' }
  - { id: 86, class: gpr32all, preferred-register: '' }
  - { id: 87, class: gpr64all, preferred-register: '' }
  - { id: 88, class: gpr64all, preferred-register: '' }
  - { id: 89, class: gpr64all, preferred-register: '' }
  - { id: 90, class: gpr64all, preferred-register: '' }
  - { id: 91, class: gpr64all, preferred-register: '' }
  - { id: 92, class: gpr64common, preferred-register: '' }
  - { id: 93, class: gpr64common, preferred-register: '' }
  - { id: 94, class: gpr64common, preferred-register: '' }
  - { id: 95, class: gpr64common, preferred-register: '' }
  - { id: 96, class: gpr64common, preferred-register: '' }
  - { id: 97, class: gpr32, preferred-register: '' }
  - { id: 98, class: ppr_3b, preferred-register: '' }
  - { id: 99, class: zpr, preferred-register: '' }
  - { id: 100, class: zpr, preferred-register: '' }
  - { id: 101, class: ppr_3b, preferred-register: '' }
  - { id: 102, class: ppr_3b, preferred-register: '' }
  - { id: 103, class: ppr_3b, preferred-register: '' }
  - { id: 104, class: zpr, preferred-register: '' }
  - { id: 105, class: zpr, preferred-register: '' }
  - { id: 106, class: zpr, preferred-register: '' }
  - { id: 107, class: zpr, preferred-register: '' }
  - { id: 108, class: zpr, preferred-register: '' }
  - { id: 109, class: zpr, preferred-register: '' }
  - { id: 110, class: zpr, preferred-register: '' }
  - { id: 111, class: gpr64sp, preferred-register: '' }
  - { id: 112, class: gpr64sp, preferred-register: '' }
  - { id: 113, class: gpr64sp, preferred-register: '' }
  - { id: 114, class: gpr64sp, preferred-register: '' }
  - { id: 115, class: gpr64sp, preferred-register: '' }
  - { id: 116, class: gpr64, preferred-register: '' }
  - { id: 117, class: gpr64common, preferred-register: '' }
  - { id: 118, class: gpr64common, preferred-register: '' }
  - { id: 119, class: gpr64common, preferred-register: '' }
  - { id: 120, class: gpr64common, preferred-register: '' }
  - { id: 121, class: gpr64common, preferred-register: '' }
  - { id: 122, class: gpr64common, preferred-register: '' }
  - { id: 123, class: gpr64common, preferred-register: '' }
  - { id: 124, class: gpr64common, preferred-register: '' }
  - { id: 125, class: fpr64, preferred-register: '' }
  - { id: 126, class: gpr32all, preferred-register: '' }
  - { id: 127, class: gpr32common, preferred-register: '' }
  - { id: 128, class: gpr32, preferred-register: '' }
  - { id: 129, class: gpr32, preferred-register: '' }
  - { id: 130, class: gpr64sp, preferred-register: '' }
  - { id: 131, class: gpr64all, preferred-register: '' }
  - { id: 132, class: gpr32all, preferred-register: '' }
  - { id: 133, class: gpr64common, preferred-register: '' }
liveins:
  - { reg: '$x0', virtual-reg: '%30' }
frameInfo:
  isFrameAddressTaken: false
  isReturnAddressTaken: false
  hasStackMap:     false
  hasPatchPoint:   false
  stackSize:       0
  offsetAdjustment: 0
  maxAlignment:    1
  adjustsStack:    true
  hasCalls:        true
  stackProtector:  ''
  functionContext: ''
  maxCallFrameSize: 0
  cvBytesOfCalleeSavedRegisters: 0
  hasOpaqueSPAdjustment: false
  hasVAStart:      false
  hasMustTailInVarArgFunc: false
  hasTailCall:     true
  localFrameSize:  0
  savePoint:       ''
  restorePoint:    ''
fixedStack:      []
stack:           []
entry_values:    []
callSites:       []
debugValueSubstitutions: []
constants:       []
machineFunctionInfo: {}
body:             |
  bb.0.entry:
    successors: %bb.2(0x50000000), %bb.1(0x30000000)
    liveins: $x0
  
    %30:gpr64common = COPY $x0
    %31:gpr64common = LDRXui %30, 4 :: (load (s64) from %ir.arg_info, !tbaa !4)
    %32:gpr32common = LDRWui killed %31, 0 :: (load (s32) from %ir.0, !tbaa !11)
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    %33:gpr64common = MOVaddr target-flags(aarch64-page) @__func__.s, target-flags(aarch64-pageoff, aarch64-nc) @__func__.s
    $x0 = COPY %33
    BL @initialise_arrays, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    %35:gpr64all = COPY $xzr
    $x0 = COPY %30
    $x1 = COPY %35
    BL @gettimeofday, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit $x1, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    dead $wzr = SUBSWri killed %32, 0, 0, implicit-def $nzcv
    Bcc 12, %bb.2, implicit $nzcv
    B %bb.1
  
  bb.1.vector.ph.preheader:
    successors: %bb.6(0x80000000)
  
    %39:gpr32all = COPY $wzr
    %38:gpr32all = COPY %39
    %45:gpr64common = MOVaddr target-flags(aarch64-page) @a, target-flags(aarch64-pageoff, aarch64-nc) @a
    %46:gpr64common = MOVaddr target-flags(aarch64-page) @b, target-flags(aarch64-pageoff, aarch64-nc) @b
    %47:gpr64common = MOVaddr target-flags(aarch64-page) @e, target-flags(aarch64-pageoff, aarch64-nc) @e
    %48:gpr64common = MOVaddr target-flags(aarch64-page) @d, target-flags(aarch64-pageoff, aarch64-nc) @d
    %49:gpr64common = MOVaddr target-flags(aarch64-page) @c, target-flags(aarch64-pageoff, aarch64-nc) @c
    %50:gpr32 = MOVi32imm 4000
    %51:ppr_3b = PTRUE_D 31
    %77:gpr64common = MOVaddr target-flags(aarch64-page) @aa, target-flags(aarch64-pageoff, aarch64-nc) @aa
    %78:gpr64common = MOVaddr target-flags(aarch64-page) @bb, target-flags(aarch64-pageoff, aarch64-nc) @bb
    %79:gpr64common = MOVaddr target-flags(aarch64-page) @cc, target-flags(aarch64-pageoff, aarch64-nc) @cc
    %80:fpr64 = FMOVD0
    %83:gpr32 = MOVi32imm 50000
    B %bb.6
  
  bb.2.vector.ph106.preheader:
    successors: %bb.3(0x80000000)
  
    %86:gpr32all = COPY $wzr
    %85:gpr32all = COPY %86
    %92:gpr64common = MOVaddr target-flags(aarch64-page) @a, target-flags(aarch64-pageoff, aarch64-nc) @a
    %93:gpr64common = MOVaddr target-flags(aarch64-page) @b, target-flags(aarch64-pageoff, aarch64-nc) @b
    %94:gpr64common = MOVaddr target-flags(aarch64-page) @e, target-flags(aarch64-pageoff, aarch64-nc) @e
    %95:gpr64common = MOVaddr target-flags(aarch64-page) @d, target-flags(aarch64-pageoff, aarch64-nc) @d
    %96:gpr64common = MOVaddr target-flags(aarch64-page) @c, target-flags(aarch64-pageoff, aarch64-nc) @c
    %97:gpr32 = MOVi32imm 4000
    %98:ppr_3b = PTRUE_D 31
    %122:gpr64common = MOVaddr target-flags(aarch64-page) @aa, target-flags(aarch64-pageoff, aarch64-nc) @aa
    %123:gpr64common = MOVaddr target-flags(aarch64-page) @bb, target-flags(aarch64-pageoff, aarch64-nc) @bb
    %124:gpr64common = MOVaddr target-flags(aarch64-page) @cc, target-flags(aarch64-pageoff, aarch64-nc) @cc
    %125:fpr64 = FMOVD0
    %128:gpr32 = MOVi32imm 50000
  
  bb.3.vector.ph106:
    successors: %bb.4(0x80000000)
  
    %0:gpr32sp = PHI %85, %bb.2, %14, %bb.5
    %91:gpr64all = COPY %92
    %90:gpr64all = COPY %93
    %89:gpr64all = COPY %94
    %88:gpr64all = COPY %95
    %87:gpr64all = COPY %96
    %1:gpr64all = SUBREG_TO_REG 0, %97, %subreg.sub_32
  
  bb.4.vector.body111:
    successors: %bb.4(0x7c000000), %bb.5(0x04000000)
  
    %2:gpr64sp = PHI %87, %bb.3, %12, %bb.4
    %3:gpr64sp = PHI %88, %bb.3, %11, %bb.4
    %4:gpr64sp = PHI %89, %bb.3, %10, %bb.4
    %5:gpr64sp = PHI %90, %bb.3, %9, %bb.4
    %6:gpr64sp = PHI %91, %bb.3, %8, %bb.4
    %7:gpr64sp = PHI %1, %bb.3, %13, %bb.4
    %99:zpr = LD1D_IMM %98, %6, 0 :: (load unknown-size from %ir.lsr.iv, align 64, !tbaa !13)
    %100:zpr = LD1D_IMM %98, %5, 0 :: (load unknown-size from %ir.lsr.iv122, align 64, !tbaa !13)
    %102:ppr_3b = nnan ninf nsz arcp contract afn reassoc nofpexcept FCMGT_PPzZZ_D %98, %99, %100
    %103:ppr_3b = nofpexcept FCMGE_PPzZZ_D %98, %100, %99
    %104:zpr = LD1D_IMM %98, %4, 0 :: (load unknown-size from %ir.lsr.iv124, align 64, !tbaa !13)
    %105:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_D_UNDEF %98, %99, %104, %104
    ST1D_IMM killed %105, %103, %5, 0 :: (store unknown-size into %ir.lsr.iv122, align 8, !tbaa !13)
    %106:zpr = LD1D_IMM %98, %3, 0 :: (load unknown-size from %ir.lsr.iv126, align 64, !tbaa !13)
    %107:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_D_UNDEF %98, %99, %106, %106
    ST1D_IMM killed %107, %103, %2, 0 :: (store unknown-size into %ir.lsr.iv128, align 8, !tbaa !13)
    %108:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_D_UNDEF %98, %99, %106, %100
    ST1D_IMM killed %108, %102, %6, 0 :: (store unknown-size into %ir.lsr.iv, align 8, !tbaa !13)
    %109:zpr = LD1D_IMM %98, %2, 0 :: (load unknown-size from %ir.lsr.iv128, align 64, !tbaa !13)
    %110:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_D_UNDEF %98, killed %109, %106, %106
    ST1D_IMM killed %110, %102, %2, 0 :: (store unknown-size into %ir.lsr.iv128, align 8, !tbaa !13)
    %111:gpr64sp = ADDXri %6, 64, 0
    %8:gpr64all = COPY %111
    %112:gpr64sp = ADDXri %5, 64, 0
    %9:gpr64all = COPY %112
    %113:gpr64sp = ADDXri %4, 64, 0
    %10:gpr64all = COPY %113
    %114:gpr64sp = ADDXri %3, 64, 0
    %11:gpr64all = COPY %114
    %115:gpr64sp = ADDXri %2, 64, 0
    %12:gpr64all = COPY %115
    %116:gpr64 = SUBSXri %7, 1, 0, implicit-def $nzcv
    %13:gpr64all = COPY %116
    Bcc 1, %bb.4, implicit $nzcv
    B %bb.5
  
  bb.5.for.cond.cleanup4.split.us.us:
    successors: %bb.8(0x04000000), %bb.3(0x7c000000)
  
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    $x0 = COPY %92
    $x1 = COPY %93
    $x2 = COPY %96
    $x3 = COPY %95
    $x4 = COPY %94
    $x5 = COPY %122
    $x6 = COPY %123
    $x7 = COPY %124
    $d0 = COPY %125
    BL @dummy, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit $x1, implicit $x2, implicit $x3, implicit $x4, implicit $x5, implicit $x6, implicit $x7, implicit $d0, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    %127:gpr32common = nuw nsw ADDWri %0, 1, 0
    %14:gpr32all = COPY %127
    dead $wzr = SUBSWrr %127, %128, implicit-def $nzcv
    Bcc 0, %bb.8, implicit $nzcv
    B %bb.3
  
  bb.6.vector.ph:
    successors: %bb.7(0x80000000)
  
    %15:gpr32sp = PHI %38, %bb.1, %29, %bb.9
    %44:gpr64all = COPY %45
    %43:gpr64all = COPY %46
    %42:gpr64all = COPY %47
    %41:gpr64all = COPY %48
    %40:gpr64all = COPY %49
    %16:gpr64all = SUBREG_TO_REG 0, %50, %subreg.sub_32
  
  bb.7.vector.body:
    successors: %bb.7(0x7c000000), %bb.9(0x04000000)
  
    %17:gpr64sp = PHI %40, %bb.6, %27, %bb.7
    %18:gpr64sp = PHI %41, %bb.6, %26, %bb.7
    %19:gpr64sp = PHI %42, %bb.6, %25, %bb.7
    %20:gpr64sp = PHI %43, %bb.6, %24, %bb.7
    %21:gpr64sp = PHI %44, %bb.6, %23, %bb.7
    %22:gpr64sp = PHI %16, %bb.6, %28, %bb.7
    %52:zpr = LD1D_IMM %51, %21, 0 :: (load unknown-size from %ir.lsr.iv131, align 64, !tbaa !13)
    %53:zpr = LD1D_IMM %51, %20, 0 :: (load unknown-size from %ir.lsr.iv133, align 64, !tbaa !13)
    %55:ppr_3b = nnan ninf nsz arcp contract afn reassoc nofpexcept FCMGT_PPzZZ_D %51, %52, %53
    %56:ppr_3b = nofpexcept FCMGE_PPzZZ_D %51, %53, %52
    %57:zpr = LD1D_IMM %51, %19, 0 :: (load unknown-size from %ir.lsr.iv135, align 64, !tbaa !13)
    %58:zpr = nnan ninf nsz arcp contract afn reassoc nofpexcept FMUL_ZZZ_D %57, %57
    %59:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_D_UNDEF %51, %52, %57, %57
    ST1D_IMM killed %59, killed %56, %20, 0 :: (store unknown-size into %ir.lsr.iv133, align 8, !tbaa !13)
    %60:zpr = LD1D_IMM %51, %18, 0 :: (load unknown-size from %ir.lsr.iv137, align 64, !tbaa !13)
    %61:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_D_UNDEF %51, %52, %60, %53
    ST1D_IMM killed %61, %55, %21, 0 :: (store unknown-size into %ir.lsr.iv131, align 8, !tbaa !13)
    %62:zpr = nnan ninf nsz arcp contract afn reassoc nofpexcept FMUL_ZZZ_D %60, %60
    %63:zpr = SEL_ZPZZ_D %55, killed %62, killed %58
    %64:zpr = LD1D_IMM %51, %17, 0 :: (load unknown-size from %ir.lsr.iv139, align 64, !tbaa !13)
    %65:zpr = nnan ninf nsz arcp contract afn reassoc nofpexcept FADD_ZZZ_D killed %64, killed %63
    ST1D_IMM killed %65, %51, %17, 0 :: (store unknown-size into %ir.lsr.iv139, align 64, !tbaa !13)
    %66:gpr64sp = ADDXri %21, 64, 0
    %23:gpr64all = COPY %66
    %67:gpr64sp = ADDXri %20, 64, 0
    %24:gpr64all = COPY %67
    %68:gpr64sp = ADDXri %19, 64, 0
    %25:gpr64all = COPY %68
    %69:gpr64sp = ADDXri %18, 64, 0
    %26:gpr64all = COPY %69
    %70:gpr64sp = ADDXri %17, 64, 0
    %27:gpr64all = COPY %70
    %71:gpr64 = SUBSXri %22, 1, 0, implicit-def $nzcv
    %28:gpr64all = COPY %71
    Bcc 1, %bb.7, implicit $nzcv
    B %bb.9
  
  bb.8.for.cond.cleanup:
    %130:gpr64sp = nuw ADDXri %30, 16, 0
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    %131:gpr64all = COPY $xzr
    $x0 = COPY %130
    $x1 = COPY %131
    BL @gettimeofday, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit $x1, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    %133:gpr64common = MOVaddr target-flags(aarch64-page) @__func__.s, target-flags(aarch64-pageoff, aarch64-nc) @__func__.s
    $x0 = COPY %133
    TCRETURNdi @calc_checksum, 0, csr_aarch64_aapcs, implicit $sp, implicit $x0
  
  bb.9.for.cond.cleanup4.split:
    successors: %bb.8(0x04000000), %bb.6(0x7c000000)
  
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    $x0 = COPY %45
    $x1 = COPY %46
    $x2 = COPY %49
    $x3 = COPY %48
    $x4 = COPY %47
    $x5 = COPY %77
    $x6 = COPY %78
    $x7 = COPY %79
    $d0 = COPY %80
    BL @dummy, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit $x1, implicit $x2, implicit $x3, implicit $x4, implicit $x5, implicit $x6, implicit $x7, implicit $d0, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    %82:gpr32common = nuw nsw ADDWri %15, 1, 0
    %29:gpr32all = COPY %82
    dead $wzr = SUBSWrr %82, %83, implicit-def $nzcv
    Bcc 0, %bb.8, implicit $nzcv
    B %bb.6

...
