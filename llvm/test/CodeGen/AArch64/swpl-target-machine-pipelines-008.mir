#RUN: llc %s -mcpu=a64fx -ffj-swp -O2 -start-before=aarch64-swpipeliner -o /dev/null 2>&1 | FileCheck %s

#CHECK:DBG(AArch64SwplTargetMachine::getPipelines): MI: %217:zpr = nnan ninf nsz arcp contract afn reassoc FSQRT_ZPmZ_UNDEF_D %119:zpr, %88:ppr_3b, killed %216:zpr
#CHECK-NEXT:  ResourceID: SIMDFP_SVE_OP+19
#CHECK-NEXT:  latency: 80
#CHECK-NEXT:  seqDecode: false
#CHECK-NEXT:  stage/resource(): 0/FLA, 1/FLA, 2/FLA, 3/FLA, 4/FLA, 5/FLA, 6/FLA, 7/FLA, 8/FLA, 9/FLA, 10/FLA, 11/FLA, 12/FLA, 13/FLA, 14/FLA, 15/FLA, 16/FLA, 17/FLA, 18/FLA, 19/FLA, 20/FLA, 21/FLA, 22/FLA, 23/FLA, 24/FLA, 25/FLA, 26/FLA, 27/FLA, 28/FLA, 29/FLA, 30/FLA, 31/FLA, 32/FLA, 33/FLA, 34/FLA, 35/FLA, 36/FLA, 37/FLA, 38/FLA, 39/FLA, 40/FLA, 41/FLA, 42/FLA, 43/FLA, 44/FLA, 45/FLA, 46/FLA, 47/FLA, 48/FLA, 49/FLA, 50/FLA, 51/FLA, 52/FLA, 53/FLA, 54/FLA, 55/FLA, 56/FLA, 57/FLA, 58/FLA, 59/FLA, 60/FLA, 61/FLA, 62/FLA, 63/FLA, 64/FLA, 65/FLA, 66/FLA, 67/FLA, 68/FLA, 69/FLA, 70/FLA, 71/FLA, 72/FLA, 73/FLA, 74/FLA, 75/FLA, 76/FLA, 77/FLA, 78/FLA, 79/FLA

#CHECK:DBG(AArch64SwplTargetMachine::getPipelines): MI: %220:zpr = nnan ninf nsz arcp contract afn reassoc FDIV_ZPZZ_UNDEF_D %88:ppr_3b, %122:zpr, killed %217:zpr
#CHECK-NEXT:  ResourceID: SIMDFP_SVE_OP+19
#CHECK-NEXT:  latency: 80
#CHECK-NEXT:  seqDecode: false
#CHECK-NEXT:  stage/resource(): 0/FLA, 1/FLA, 2/FLA, 3/FLA, 4/FLA, 5/FLA, 6/FLA, 7/FLA, 8/FLA, 9/FLA, 10/FLA, 11/FLA, 12/FLA, 13/FLA, 14/FLA, 15/FLA, 16/FLA, 17/FLA, 18/FLA, 19/FLA, 20/FLA, 21/FLA, 22/FLA, 23/FLA, 24/FLA, 25/FLA, 26/FLA, 27/FLA, 28/FLA, 29/FLA, 30/FLA, 31/FLA, 32/FLA, 33/FLA, 34/FLA, 35/FLA, 36/FLA, 37/FLA, 38/FLA, 39/FLA, 40/FLA, 41/FLA, 42/FLA, 43/FLA, 44/FLA, 45/FLA, 46/FLA, 47/FLA, 48/FLA, 49/FLA, 50/FLA, 51/FLA, 52/FLA, 53/FLA, 54/FLA, 55/FLA, 56/FLA, 57/FLA, 58/FLA, 59/FLA, 60/FLA, 61/FLA, 62/FLA, 63/FLA, 64/FLA, 65/FLA, 66/FLA, 67/FLA, 68/FLA, 69/FLA, 70/FLA, 71/FLA, 72/FLA, 73/FLA, 74/FLA, 75/FLA, 76/FLA, 77/FLA, 78/FLA, 79/FLA

--- |
  ; ModuleID = 'nbody2_exclude_fapp.c'
  source_filename = "nbody2_exclude_fapp.c"
  target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
  target triple = "aarch64-unknown-linux-gnu"
  
  @rep = dso_local local_unnamed_addr global i32 0, align 4
  @size = dso_local local_unnamed_addr global i32 0, align 4
  @px = dso_local local_unnamed_addr global [64 x float] zeroinitializer, align 4
  @py = dso_local local_unnamed_addr global [64 x float] zeroinitializer, align 4
  @pz = dso_local local_unnamed_addr global [64 x float] zeroinitializer, align 4
  @vx = dso_local global [64 x float] zeroinitializer, align 4
  @vy = dso_local local_unnamed_addr global [64 x float] zeroinitializer, align 4
  @vz = dso_local local_unnamed_addr global [64 x float] zeroinitializer, align 4
  @m = dso_local local_unnamed_addr global [64 x float] zeroinitializer, align 4
  @DT = dso_local local_unnamed_addr global i32 0, align 4
  
  ; Function Attrs: nounwind uwtable vscale_range(2,2)
  define dso_local void @test() local_unnamed_addr #0 {
  entry:
    %0 = load i32, ptr @rep, align 4, !tbaa !6
    %cmp64 = icmp sgt i32 %0, 0
    br i1 %cmp64, label %for.cond1.preheader.lr.ph, label %for.cond.cleanup
  
  for.cond1.preheader.lr.ph:                        ; preds = %entry
    %1 = load i32, ptr @size, align 4, !tbaa !6
    %wide.trip.count = zext i32 %1 to i64
    %cmp261 = icmp sgt i32 %1, 0
    br i1 %cmp261, label %for.cond1.preheader.us.us.preheader, label %for.cond.cleanup
  
  for.cond1.preheader.us.us.preheader:              ; preds = %for.cond1.preheader.lr.ph
    %2 = trunc i64 %wide.trip.count to i32
    %3 = trunc i64 %wide.trip.count to i32
    %4 = add nsw i32 %2, -1
    %idxprom16.le.us.us.us.phi.trans.insert.phi.trans.insert = zext i32 %4 to i64
    %arrayidx17.le.us.us.us.phi.trans.insert.phi.trans.insert = getelementptr inbounds [64 x float], ptr @px, i64 0, i64 %idxprom16.le.us.us.us.phi.trans.insert.phi.trans.insert
    %.pre.pre = load float, ptr %arrayidx17.le.us.us.us.phi.trans.insert.phi.trans.insert, align 4, !tbaa !10
    %arrayidx20.le.us.us.us.phi.trans.insert.phi.trans.insert = getelementptr inbounds [64 x float], ptr @py, i64 0, i64 %idxprom16.le.us.us.us.phi.trans.insert.phi.trans.insert
    %.pre82.pre = load float, ptr %arrayidx20.le.us.us.us.phi.trans.insert.phi.trans.insert, align 4, !tbaa !10
    %arrayidx24.le.us.us.us.phi.trans.insert.phi.trans.insert = getelementptr inbounds [64 x float], ptr @pz, i64 0, i64 %idxprom16.le.us.us.us.phi.trans.insert.phi.trans.insert
    %.pre84.pre = load float, ptr %arrayidx24.le.us.us.us.phi.trans.insert.phi.trans.insert, align 4, !tbaa !10
    %conv18.le.us.us.us = fpext float %.pre.pre to double
    %conv21.le.us.us.us = fpext float %.pre82.pre to double
    %conv25.le.us.us.us = fpext float %.pre84.pre to double
    %n.vec = and i64 %wide.trip.count, 4294967288
    %broadcast.splatinsert = insertelement <vscale x 4 x double> poison, double %conv18.le.us.us.us, i64 0
    %broadcast.splat = shufflevector <vscale x 4 x double> %broadcast.splatinsert, <vscale x 4 x double> poison, <vscale x 4 x i32> zeroinitializer
    %broadcast.splatinsert89 = insertelement <vscale x 4 x double> poison, double %conv21.le.us.us.us, i64 0
    %broadcast.splat90 = shufflevector <vscale x 4 x double> %broadcast.splatinsert89, <vscale x 4 x double> poison, <vscale x 4 x i32> zeroinitializer
    %broadcast.splatinsert91 = insertelement <vscale x 4 x double> poison, double %conv25.le.us.us.us, i64 0
    %broadcast.splat92 = shufflevector <vscale x 4 x double> %broadcast.splatinsert91, <vscale x 4 x double> poison, <vscale x 4 x i32> zeroinitializer
    %5 = add nsw i64 %n.vec, -8
    %6 = lshr i64 %5, 3
    %7 = add nuw nsw i64 %6, 1
    br label %for.cond1.preheader.us.us
  
  for.cond1.preheader.us.us:                        ; preds = %for.cond1.preheader.us.us.preheader, %for.cond1.for.cond.cleanup3_crit_edge.split.us.us.us
    %t.066.us.us = phi i32 [ %inc39.us.us, %for.cond1.for.cond.cleanup3_crit_edge.split.us.us.us ], [ 0, %for.cond1.preheader.us.us.preheader ]
    %8 = icmp ult i32 %3, 8
    br i1 %8, label %for.body4.us.us.us.preheader, label %vector.body.preheader
  
  vector.body.preheader:                            ; preds = %for.cond1.preheader.us.us
    %9 = call i64 @llvm.start.loop.iterations.i64(i64 %7)
    br label %vector.body
  
  vector.body:                                      ; preds = %vector.body.preheader, %vector.body
    %lsr.iv98 = phi ptr [ @vx, %vector.body.preheader ], [ %uglygep99, %vector.body ]
    %lsr.iv96 = phi ptr [ @pz, %vector.body.preheader ], [ %uglygep97, %vector.body ]
    %lsr.iv94 = phi ptr [ @py, %vector.body.preheader ], [ %uglygep95, %vector.body ]
    %lsr.iv = phi ptr [ @px, %vector.body.preheader ], [ %uglygep, %vector.body ]
    %10 = phi i64 [ %9, %vector.body.preheader ], [ %27, %vector.body ]
    %wide.load = load <vscale x 4 x float>, ptr %lsr.iv, align 4, !tbaa !10
    %wide.load87 = load <vscale x 4 x float>, ptr %lsr.iv94, align 4, !tbaa !10
    %wide.load88 = load <vscale x 4 x float>, ptr %lsr.iv96, align 4, !tbaa !10
    %11 = fpext <vscale x 4 x float> %wide.load to <vscale x 4 x double>
    %12 = fpext <vscale x 4 x float> %wide.load87 to <vscale x 4 x double>
    %13 = fpext <vscale x 4 x float> %wide.load88 to <vscale x 4 x double>
    %14 = fsub fast <vscale x 4 x double> %broadcast.splat, %11
    %15 = fsub fast <vscale x 4 x double> %broadcast.splat90, %12
    %16 = fsub fast <vscale x 4 x double> %broadcast.splat92, %13
    %17 = fmul fast <vscale x 4 x double> %14, %14
    %18 = fmul fast <vscale x 4 x double> %15, %15
    %19 = fadd fast <vscale x 4 x double> %18, %17
    %20 = fmul fast <vscale x 4 x double> %16, %16
    %21 = fadd fast <vscale x 4 x double> %19, %20
    %22 = tail call fast <vscale x 4 x double> @llvm.sqrt.nxv4f64(<vscale x 4 x double> %21)
    %23 = fdiv fast <vscale x 4 x double> shufflevector (<vscale x 4 x double> insertelement (<vscale x 4 x double> poison, double 1.000000e+00, i32 0), <vscale x 4 x double> poison, <vscale x 4 x i32> zeroinitializer), %22
    %wide.load93 = load <vscale x 4 x float>, ptr %lsr.iv98, align 4, !tbaa !10
    %24 = fpext <vscale x 4 x float> %wide.load93 to <vscale x 4 x double>
    %25 = fadd fast <vscale x 4 x double> %23, %24
    %26 = fptrunc <vscale x 4 x double> %25 to <vscale x 4 x float>
    store <vscale x 4 x float> %26, ptr %lsr.iv98, align 4, !tbaa !10
    %uglygep = getelementptr i8, ptr %lsr.iv, i64 32
    %uglygep95 = getelementptr i8, ptr %lsr.iv94, i64 32
    %uglygep97 = getelementptr i8, ptr %lsr.iv96, i64 32
    %uglygep99 = getelementptr i8, ptr %lsr.iv98, i64 32
    %27 = call i64 @llvm.loop.decrement.reg.i64(i64 %10, i64 1)
    %28 = icmp ne i64 %27, 0
    br i1 %28, label %vector.body, label %middle.block, !llvm.loop !12
  
  middle.block:                                     ; preds = %vector.body
    %29 = icmp eq i64 %n.vec, %wide.trip.count
    br i1 %29, label %for.cond1.for.cond.cleanup3_crit_edge.split.us.us.us, label %for.body4.us.us.us.preheader
  
  for.body4.us.us.us.preheader:                     ; preds = %for.cond1.preheader.us.us, %middle.block
    %indvars.iv.ph = phi i64 [ %n.vec, %middle.block ], [ 0, %for.cond1.preheader.us.us ]
    %30 = shl nuw nsw i64 %indvars.iv.ph, 2
    %uglygep101 = getelementptr i8, ptr @px, i64 %30
    %uglygep104 = getelementptr i8, ptr @py, i64 %30
    %uglygep107 = getelementptr i8, ptr @pz, i64 %30
    %uglygep110 = getelementptr i8, ptr @vx, i64 %30
    %31 = sub i64 %wide.trip.count, %indvars.iv.ph
    %32 = call i64 @llvm.start.loop.iterations.i64(i64 %31)
    br label %for.body4.us.us.us
  
  for.body4.us.us.us:                               ; preds = %for.body4.us.us.us.preheader, %for.body4.us.us.us
    %lsr.iv111 = phi ptr [ %uglygep110, %for.body4.us.us.us.preheader ], [ %uglygep112, %for.body4.us.us.us ]
    %lsr.iv108 = phi ptr [ %uglygep107, %for.body4.us.us.us.preheader ], [ %uglygep109, %for.body4.us.us.us ]
    %lsr.iv105 = phi ptr [ %uglygep104, %for.body4.us.us.us.preheader ], [ %uglygep106, %for.body4.us.us.us ]
    %lsr.iv102 = phi ptr [ %uglygep101, %for.body4.us.us.us.preheader ], [ %uglygep103, %for.body4.us.us.us ]
    %33 = phi i64 [ %32, %for.body4.us.us.us.preheader ], [ %39, %for.body4.us.us.us ]
    %34 = load float, ptr %lsr.iv102, align 4, !tbaa !10
    %35 = load float, ptr %lsr.iv105, align 4, !tbaa !10
    %36 = load float, ptr %lsr.iv108, align 4, !tbaa !10
    %conv.us.us.us = fpext float %34 to double
    %conv7.us.us.us = fpext float %35 to double
    %conv10.us.us.us = fpext float %36 to double
    %sub.le.us.us.us = fsub fast double %conv18.le.us.us.us, %conv.us.us.us
    %sub22.le.us.us.us = fsub fast double %conv21.le.us.us.us, %conv7.us.us.us
    %sub26.le.us.us.us = fsub fast double %conv25.le.us.us.us, %conv10.us.us.us
    %mul.le.us.us.us = fmul fast double %sub.le.us.us.us, %sub.le.us.us.us
    %mul27.le.us.us.us = fmul fast double %sub22.le.us.us.us, %sub22.le.us.us.us
    %add.le.us.us.us = fadd fast double %mul27.le.us.us.us, %mul.le.us.us.us
    %mul28.le.us.us.us = fmul fast double %sub26.le.us.us.us, %sub26.le.us.us.us
    %add29.le.us.us.us = fadd fast double %add.le.us.us.us, %mul28.le.us.us.us
    %37 = tail call fast double @llvm.sqrt.f64(double %add29.le.us.us.us)
    %div.le.us.us.us = fdiv fast double 1.000000e+00, %37
    %38 = load float, ptr %lsr.iv111, align 4, !tbaa !10
    %conv32.us.us.us = fpext float %38 to double
    %add33.us.us.us = fadd fast double %div.le.us.us.us, %conv32.us.us.us
    %conv34.us.us.us = fptrunc double %add33.us.us.us to float
    store float %conv34.us.us.us, ptr %lsr.iv111, align 4, !tbaa !10
    %uglygep103 = getelementptr i8, ptr %lsr.iv102, i64 4
    %uglygep106 = getelementptr i8, ptr %lsr.iv105, i64 4
    %uglygep109 = getelementptr i8, ptr %lsr.iv108, i64 4
    %uglygep112 = getelementptr i8, ptr %lsr.iv111, i64 4
    %39 = call i64 @llvm.loop.decrement.reg.i64(i64 %33, i64 1)
    %40 = icmp ne i64 %39, 0
    br i1 %40, label %for.body4.us.us.us, label %for.cond1.for.cond.cleanup3_crit_edge.split.us.us.us, !llvm.loop !16
  
  for.cond1.for.cond.cleanup3_crit_edge.split.us.us.us: ; preds = %for.body4.us.us.us, %middle.block
    %inc39.us.us = add nuw nsw i32 %t.066.us.us, 1
    %exitcond80.not = icmp eq i32 %inc39.us.us, %0
    br i1 %exitcond80.not, label %for.cond.cleanup, label %for.cond1.preheader.us.us, !llvm.loop !17
  
  for.cond.cleanup:                                 ; preds = %for.cond1.for.cond.cleanup3_crit_edge.split.us.us.us, %for.cond1.preheader.lr.ph, %entry
    ret void
  }
  
  ; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
  declare double @llvm.sqrt.f64(double) #1
  
  ; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
  declare <vscale x 4 x double> @llvm.sqrt.nxv4f64(<vscale x 4 x double>) #3
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.start.loop.iterations.i64(i64) #4
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.loop.decrement.reg.i64(i64, i64) #4
  
  attributes #0 = { nounwind uwtable vscale_range(2,2) "approx-func-fp-math"="true" "frame-pointer"="non-leaf" "min-legal-vector-width"="0" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+crypto,+fp-armv8,+fullfp16,+lse,+neon,+outline-atomics,+ras,+rdm,+sha2,+sve,+v8.2a" "unsafe-fp-math"="true" }
  attributes #1 = { mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn }
  attributes #2 = { "approx-func-fp-math"="true" "frame-pointer"="non-leaf" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+crypto,+fp-armv8,+fullfp16,+lse,+neon,+outline-atomics,+ras,+rdm,+sha2,+sve,+v8.2a" "unsafe-fp-math"="true" }
  attributes #3 = { nocallback nofree nosync nounwind readnone speculatable willreturn }
  attributes #4 = { nocallback noduplicate nofree nosync nounwind willreturn }
  attributes #5 = { nounwind }
  
  !llvm.module.flags = !{!0, !1, !2, !3, !4}
  !llvm.ident = !{!5}
  
  !0 = !{i32 1, !"wchar_size", i32 4}
  !1 = !{i32 7, !"PIC Level", i32 2}
  !2 = !{i32 7, !"PIE Level", i32 2}
  !3 = !{i32 7, !"uwtable", i32 2}
  !4 = !{i32 7, !"frame-pointer", i32 1}
  !5 = !{!"clang version 15.0.4 (http://172.16.1.70:10081/a64fx-swpl/llvm-project.git 457709738ca2bb452bf95c8a66801e43aeadbdc3)"}
  !6 = !{!7, !7, i64 0}
  !7 = !{!"int", !8, i64 0}
  !8 = !{!"omnipotent char", !9, i64 0}
  !9 = !{!"Simple C/C++ TBAA"}
  !10 = !{!11, !11, i64 0}
  !11 = !{!"float", !8, i64 0}
  !12 = distinct !{!12, !13, !14, !15}
  !13 = !{!"llvm.loop.mustprogress"}
  !14 = !{!"llvm.loop.unroll.disable"}
  !15 = !{!"llvm.loop.isvectorized", i32 1}
  !16 = distinct !{!16, !13, !14, !15}
  !17 = distinct !{!17, !13, !14}

...
---
name:            test
alignment:       8
exposesReturnsTwice: false
legalized:       false
regBankSelected: false
selected:        false
failedISel:      false
tracksRegLiveness: true
hasWinCFI:       false
callsEHReturn:   false
callsUnwindInit: false
hasEHCatchret:   false
hasEHScopes:     false
hasEHFunclets:   false
failsVerification: false
tracksDebugUserValues: false
registers:
  - { id: 0, class: gpr32, preferred-register: '' }
  - { id: 1, class: gpr64, preferred-register: '' }
  - { id: 2, class: gpr32sp, preferred-register: '' }
  - { id: 3, class: fpr64, preferred-register: '' }
  - { id: 4, class: fpr64, preferred-register: '' }
  - { id: 5, class: fpr64, preferred-register: '' }
  - { id: 6, class: gpr64, preferred-register: '' }
  - { id: 7, class: zpr, preferred-register: '' }
  - { id: 8, class: zpr, preferred-register: '' }
  - { id: 9, class: zpr, preferred-register: '' }
  - { id: 10, class: zpr, preferred-register: '' }
  - { id: 11, class: zpr, preferred-register: '' }
  - { id: 12, class: zpr, preferred-register: '' }
  - { id: 13, class: gpr64all, preferred-register: '' }
  - { id: 14, class: gpr32sp, preferred-register: '' }
  - { id: 15, class: gpr64all, preferred-register: '' }
  - { id: 16, class: gpr64sp, preferred-register: '' }
  - { id: 17, class: gpr64sp, preferred-register: '' }
  - { id: 18, class: gpr64sp, preferred-register: '' }
  - { id: 19, class: gpr64sp, preferred-register: '' }
  - { id: 20, class: gpr64sp, preferred-register: '' }
  - { id: 21, class: gpr64all, preferred-register: '' }
  - { id: 22, class: gpr64all, preferred-register: '' }
  - { id: 23, class: gpr64all, preferred-register: '' }
  - { id: 24, class: gpr64all, preferred-register: '' }
  - { id: 25, class: gpr64all, preferred-register: '' }
  - { id: 26, class: gpr64, preferred-register: '' }
  - { id: 27, class: gpr64all, preferred-register: '' }
  - { id: 28, class: gpr64all, preferred-register: '' }
  - { id: 29, class: gpr64all, preferred-register: '' }
  - { id: 30, class: gpr64all, preferred-register: '' }
  - { id: 31, class: gpr64all, preferred-register: '' }
  - { id: 32, class: gpr64sp, preferred-register: '' }
  - { id: 33, class: gpr64sp, preferred-register: '' }
  - { id: 34, class: gpr64sp, preferred-register: '' }
  - { id: 35, class: gpr64sp, preferred-register: '' }
  - { id: 36, class: gpr64sp, preferred-register: '' }
  - { id: 37, class: gpr64all, preferred-register: '' }
  - { id: 38, class: gpr64all, preferred-register: '' }
  - { id: 39, class: gpr64all, preferred-register: '' }
  - { id: 40, class: gpr64all, preferred-register: '' }
  - { id: 41, class: gpr64all, preferred-register: '' }
  - { id: 42, class: gpr32all, preferred-register: '' }
  - { id: 43, class: gpr64common, preferred-register: '' }
  - { id: 44, class: gpr32common, preferred-register: '' }
  - { id: 45, class: gpr32, preferred-register: '' }
  - { id: 46, class: gpr64common, preferred-register: '' }
  - { id: 47, class: gpr32, preferred-register: '' }
  - { id: 48, class: gpr32sp, preferred-register: '' }
  - { id: 49, class: gpr32, preferred-register: '' }
  - { id: 50, class: gpr32all, preferred-register: '' }
  - { id: 51, class: gpr32common, preferred-register: '' }
  - { id: 52, class: gpr32, preferred-register: '' }
  - { id: 53, class: gpr64, preferred-register: '' }
  - { id: 54, class: gpr64, preferred-register: '' }
  - { id: 55, class: gpr64common, preferred-register: '' }
  - { id: 56, class: fpr32, preferred-register: '' }
  - { id: 57, class: gpr64common, preferred-register: '' }
  - { id: 58, class: fpr32, preferred-register: '' }
  - { id: 59, class: gpr64common, preferred-register: '' }
  - { id: 60, class: fpr32, preferred-register: '' }
  - { id: 61, class: gpr64common, preferred-register: '' }
  - { id: 62, class: zpr, preferred-register: '' }
  - { id: 63, class: zpr, preferred-register: '' }
  - { id: 64, class: zpr, preferred-register: '' }
  - { id: 65, class: zpr, preferred-register: '' }
  - { id: 66, class: zpr, preferred-register: '' }
  - { id: 67, class: zpr, preferred-register: '' }
  - { id: 68, class: gpr64common, preferred-register: '' }
  - { id: 69, class: gpr64common, preferred-register: '' }
  - { id: 70, class: gpr64sp, preferred-register: '' }
  - { id: 71, class: gpr32all, preferred-register: '' }
  - { id: 72, class: gpr64all, preferred-register: '' }
  - { id: 73, class: gpr64all, preferred-register: '' }
  - { id: 74, class: gpr32, preferred-register: '' }
  - { id: 75, class: gpr64all, preferred-register: '' }
  - { id: 76, class: gpr64all, preferred-register: '' }
  - { id: 77, class: gpr64all, preferred-register: '' }
  - { id: 78, class: gpr64all, preferred-register: '' }
  - { id: 79, class: gpr64common, preferred-register: '' }
  - { id: 80, class: gpr64common, preferred-register: '' }
  - { id: 81, class: gpr64common, preferred-register: '' }
  - { id: 82, class: gpr64common, preferred-register: '' }
  - { id: 83, class: ppr_3b, preferred-register: '' }
  - { id: 84, class: zpr, preferred-register: '' }
  - { id: 85, class: zpr, preferred-register: '' }
  - { id: 86, class: zpr, preferred-register: '' }
  - { id: 87, class: zpr, preferred-register: '' }
  - { id: 88, class: ppr_3b, preferred-register: '' }
  - { id: 89, class: zpr, preferred-register: '' }
  - { id: 90, class: zpr, preferred-register: '' }
  - { id: 91, class: zpr, preferred-register: '' }
  - { id: 92, class: zpr, preferred-register: '' }
  - { id: 93, class: zpr, preferred-register: '' }
  - { id: 94, class: zpr, preferred-register: '' }
  - { id: 95, class: zpr, preferred-register: '' }
  - { id: 96, class: zpr, preferred-register: '' }
  - { id: 97, class: zpr, preferred-register: '' }
  - { id: 98, class: zpr, preferred-register: '' }
  - { id: 99, class: zpr, preferred-register: '' }
  - { id: 100, class: zpr, preferred-register: '' }
  - { id: 101, class: zpr, preferred-register: '' }
  - { id: 102, class: zpr, preferred-register: '' }
  - { id: 103, class: zpr, preferred-register: '' }
  - { id: 104, class: zpr, preferred-register: '' }
  - { id: 105, class: zpr, preferred-register: '' }
  - { id: 106, class: zpr, preferred-register: '' }
  - { id: 107, class: zpr, preferred-register: '' }
  - { id: 108, class: zpr, preferred-register: '' }
  - { id: 109, class: zpr, preferred-register: '' }
  - { id: 110, class: zpr, preferred-register: '' }
  - { id: 111, class: zpr, preferred-register: '' }
  - { id: 112, class: zpr, preferred-register: '' }
  - { id: 113, class: zpr, preferred-register: '' }
  - { id: 114, class: zpr, preferred-register: '' }
  - { id: 115, class: zpr, preferred-register: '' }
  - { id: 116, class: zpr, preferred-register: '' }
  - { id: 117, class: zpr, preferred-register: '' }
  - { id: 118, class: zpr, preferred-register: '' }
  - { id: 119, class: zpr, preferred-register: '' }
  - { id: 120, class: zpr, preferred-register: '' }
  - { id: 121, class: zpr, preferred-register: '' }
  - { id: 122, class: zpr, preferred-register: '' }
  - { id: 123, class: zpr, preferred-register: '' }
  - { id: 124, class: zpr, preferred-register: '' }
  - { id: 125, class: zpr, preferred-register: '' }
  - { id: 126, class: zpr, preferred-register: '' }
  - { id: 127, class: zpr, preferred-register: '' }
  - { id: 128, class: zpr, preferred-register: '' }
  - { id: 129, class: zpr, preferred-register: '' }
  - { id: 130, class: zpr, preferred-register: '' }
  - { id: 131, class: zpr, preferred-register: '' }
  - { id: 132, class: zpr, preferred-register: '' }
  - { id: 133, class: zpr, preferred-register: '' }
  - { id: 134, class: zpr, preferred-register: '' }
  - { id: 135, class: zpr, preferred-register: '' }
  - { id: 136, class: zpr, preferred-register: '' }
  - { id: 137, class: zpr, preferred-register: '' }
  - { id: 138, class: zpr, preferred-register: '' }
  - { id: 139, class: gpr64sp, preferred-register: '' }
  - { id: 140, class: gpr64sp, preferred-register: '' }
  - { id: 141, class: gpr64sp, preferred-register: '' }
  - { id: 142, class: gpr64sp, preferred-register: '' }
  - { id: 143, class: gpr64, preferred-register: '' }
  - { id: 144, class: gpr64, preferred-register: '' }
  - { id: 145, class: gpr64, preferred-register: '' }
  - { id: 146, class: gpr64common, preferred-register: '' }
  - { id: 147, class: gpr64, preferred-register: '' }
  - { id: 148, class: gpr64common, preferred-register: '' }
  - { id: 149, class: gpr64, preferred-register: '' }
  - { id: 150, class: gpr64common, preferred-register: '' }
  - { id: 151, class: gpr64, preferred-register: '' }
  - { id: 152, class: gpr64common, preferred-register: '' }
  - { id: 153, class: gpr64, preferred-register: '' }
  - { id: 154, class: gpr64, preferred-register: '' }
  - { id: 155, class: gpr64sp, preferred-register: '' }
  - { id: 156, class: fpr32, preferred-register: '' }
  - { id: 157, class: gpr64sp, preferred-register: '' }
  - { id: 158, class: fpr32, preferred-register: '' }
  - { id: 159, class: gpr64sp, preferred-register: '' }
  - { id: 160, class: fpr32, preferred-register: '' }
  - { id: 161, class: fpr64, preferred-register: '' }
  - { id: 162, class: fpr64, preferred-register: '' }
  - { id: 163, class: fpr64, preferred-register: '' }
  - { id: 164, class: fpr64, preferred-register: '' }
  - { id: 165, class: fpr64, preferred-register: '' }
  - { id: 166, class: fpr64, preferred-register: '' }
  - { id: 167, class: fpr64, preferred-register: '' }
  - { id: 168, class: fpr64, preferred-register: '' }
  - { id: 169, class: fpr64, preferred-register: '' }
  - { id: 170, class: fpr64, preferred-register: '' }
  - { id: 171, class: fpr64, preferred-register: '' }
  - { id: 172, class: fpr64, preferred-register: '' }
  - { id: 173, class: fpr64, preferred-register: '' }
  - { id: 174, class: fpr64, preferred-register: '' }
  - { id: 175, class: fpr32, preferred-register: '' }
  - { id: 176, class: fpr64, preferred-register: '' }
  - { id: 177, class: fpr64, preferred-register: '' }
  - { id: 178, class: fpr32, preferred-register: '' }
  - { id: 179, class: gpr64sp, preferred-register: '' }
  - { id: 180, class: gpr64, preferred-register: '' }
  - { id: 181, class: gpr32common, preferred-register: '' }
  - { id: 182, class: gpr32, preferred-register: '' }
  - { id: 183, class: gpr64common, preferred-register: '' }
  - { id: 184, class: gpr64common, preferred-register: '' }
liveins:         []
frameInfo:
  isFrameAddressTaken: false
  isReturnAddressTaken: false
  hasStackMap:     false
  hasPatchPoint:   false
  stackSize:       0
  offsetAdjustment: 0
  maxAlignment:    1
  adjustsStack:    false
  hasCalls:        false
  stackProtector:  ''
  functionContext: ''
  maxCallFrameSize: 0
  cvBytesOfCalleeSavedRegisters: 0
  hasOpaqueSPAdjustment: false
  hasVAStart:      false
  hasMustTailInVarArgFunc: false
  hasTailCall:     true
  localFrameSize:  0
  savePoint:       ''
  restorePoint:    ''
fixedStack:      []
stack:           []
callSites:       []
debugValueSubstitutions: []
constants:       []
machineFunctionInfo: {}
body:             |
  bb.0.entry:
    successors: %bb.1(0x50000000), %bb.10(0x30000000)
  
    %43:gpr64common = ADRP target-flags(aarch64-page) @rep
    %44:gpr32common = LDRWui killed %43, target-flags(aarch64-pageoff, aarch64-nc) @rep :: (dereferenceable load (s32) from @rep, !tbaa !6)
    dead $wzr = SUBSWri %44, 1, 0, implicit-def $nzcv
    Bcc 11, %bb.10, implicit $nzcv
    B %bb.1
  
  bb.1.for.cond1.preheader.lr.ph:
    successors: %bb.2(0x50000000), %bb.10(0x30000000)
  
    %46:gpr64common = ADRP target-flags(aarch64-page) @size
    %47:gpr32 = LDRWui killed %46, target-flags(aarch64-pageoff, aarch64-nc) @size :: (dereferenceable load (s32) from @size, !tbaa !6)
    %1:gpr64 = SUBREG_TO_REG 0, killed %47, %subreg.sub_32
    %48:gpr32sp = COPY %1.sub_32
    dead $wzr = SUBSWri killed %48, 1, 0, implicit-def $nzcv
    Bcc 11, %bb.10, implicit $nzcv
    B %bb.2
  
  bb.2.for.cond1.preheader.us.us.preheader:
    successors: %bb.3(0x80000000)
  
    %184:gpr64common = MOVaddr target-flags(aarch64-page) @vx, target-flags(aarch64-pageoff, aarch64-nc) @vx
    %2:gpr32sp = COPY %1.sub_32
    %51:gpr32common = nsw SUBWri %2, 1, 0
    %53:gpr64 = SUBREG_TO_REG 0, %51, %subreg.sub_32
    %54:gpr64 = UBFMXri killed %53, 62, 61
    %55:gpr64common = MOVaddr target-flags(aarch64-page) @px, target-flags(aarch64-pageoff, aarch64-nc) @px
    %56:fpr32 = LDRSroX %55, %54, 0, 0 :: (load (s32) from %ir.arrayidx17.le.us.us.us.phi.trans.insert.phi.trans.insert, !tbaa !10)
    %57:gpr64common = MOVaddr target-flags(aarch64-page) @py, target-flags(aarch64-pageoff, aarch64-nc) @py
    %58:fpr32 = LDRSroX %57, %54, 0, 0 :: (load (s32) from %ir.arrayidx20.le.us.us.us.phi.trans.insert.phi.trans.insert, !tbaa !10)
    %59:gpr64common = MOVaddr target-flags(aarch64-page) @pz, target-flags(aarch64-pageoff, aarch64-nc) @pz
    %60:fpr32 = LDRSroX %59, %54, 0, 0 :: (load (s32) from %ir.arrayidx24.le.us.us.us.phi.trans.insert.phi.trans.insert, !tbaa !10)
    %3:fpr64 = nofpexcept FCVTDSr killed %56
    %4:fpr64 = nofpexcept FCVTDSr killed %58
    %5:fpr64 = nofpexcept FCVTDSr killed %60
    %61:gpr64common = ANDXri %1, 8028
    %6:gpr64 = COPY %61
    %63:zpr = IMPLICIT_DEF
    %62:zpr = INSERT_SUBREG %63, %3, %subreg.dsub
    %8:zpr = DUP_ZZI_D killed %62, 0
    %65:zpr = IMPLICIT_DEF
    %64:zpr = INSERT_SUBREG %65, %4, %subreg.dsub
    %10:zpr = DUP_ZZI_D killed %64, 0
    %67:zpr = IMPLICIT_DEF
    %66:zpr = INSERT_SUBREG %67, %5, %subreg.dsub
    %12:zpr = DUP_ZZI_D killed %66, 0
    %68:gpr64common = nsw SUBXri %61, 8, 0
    %69:gpr64common = UBFMXri killed %68, 3, 63
    %70:gpr64sp = nuw nsw ADDXri killed %69, 1, 0
    %71:gpr32all = COPY $wzr
    %50:gpr32all = COPY %71
    %13:gpr64all = COPY %70
    %173:fpr64 = FMOVDi 112
    %83:ppr_3b = PTRUE_S 31
    %88:ppr_3b = PTRUE_D 31
    %90:zpr = IMPLICIT_DEF
    %93:zpr = IMPLICIT_DEF
    %96:zpr = IMPLICIT_DEF
    %99:zpr = IMPLICIT_DEF
    %102:zpr = IMPLICIT_DEF
    %105:zpr = IMPLICIT_DEF
    %119:zpr = IMPLICIT_DEF
    %121:zpr = IMPLICIT_DEF
    %122:zpr = FDUP_ZI_D 112
    %128:zpr = IMPLICIT_DEF
    %131:zpr = IMPLICIT_DEF
    %135:zpr = IMPLICIT_DEF
    %137:zpr = IMPLICIT_DEF
  
  bb.3.for.cond1.preheader.us.us:
    successors: %bb.11(0x40000000), %bb.4(0x40000000)
  
    %14:gpr32sp = PHI %50, %bb.2, %42, %bb.9
    dead $wzr = SUBSWri %2, 8, 0, implicit-def $nzcv
    Bcc 2, %bb.4, implicit $nzcv
  
  bb.11:
    successors: %bb.7(0x80000000)
  
    %73:gpr64all = COPY $xzr
    %72:gpr64all = COPY %73
    B %bb.7
  
  bb.4.vector.body.preheader:
    successors: %bb.5(0x80000000)
  
    %78:gpr64all = COPY %55
    %77:gpr64all = COPY %57
    %76:gpr64all = COPY %59
    %75:gpr64all = COPY %184
    %15:gpr64all = COPY %13
  
  bb.5.vector.body:
    successors: %bb.5(0x7c000000), %bb.6(0x04000000)
  
    %16:gpr64sp = PHI %75, %bb.4, %24, %bb.5
    %17:gpr64sp = PHI %76, %bb.4, %23, %bb.5
    %18:gpr64sp = PHI %77, %bb.4, %22, %bb.5
    %19:gpr64sp = PHI %78, %bb.4, %21, %bb.5
    %20:gpr64sp = PHI %15, %bb.4, %25, %bb.5
    %84:zpr = LD1W_IMM %83, %19, 0 :: (load unknown-size from %ir.lsr.iv, align 4, !tbaa !10)
    %85:zpr = LD1W_IMM %83, %18, 0 :: (load unknown-size from %ir.lsr.iv94, align 4, !tbaa !10)
    %86:zpr = LD1W_IMM %83, %17, 0 :: (load unknown-size from %ir.lsr.iv96, align 4, !tbaa !10)
    %87:zpr = UUNPKHI_ZZ_D %84
    %89:zpr = FCVT_ZPmZ_StoD_UNDEF %90, %88, killed %87
    %91:zpr = UUNPKLO_ZZ_D %84
    %92:zpr = FCVT_ZPmZ_StoD_UNDEF %93, %88, killed %91
    %94:zpr = UUNPKLO_ZZ_D %85
    %95:zpr = FCVT_ZPmZ_StoD_UNDEF %96, %88, killed %94
    %97:zpr = UUNPKHI_ZZ_D %85
    %98:zpr = FCVT_ZPmZ_StoD_UNDEF %99, %88, killed %97
    %100:zpr = UUNPKHI_ZZ_D %86
    %101:zpr = FCVT_ZPmZ_StoD_UNDEF %102, %88, killed %100
    %103:zpr = UUNPKLO_ZZ_D %86
    %104:zpr = FCVT_ZPmZ_StoD_UNDEF %105, %88, killed %103
    %106:zpr = nnan ninf nsz arcp contract afn reassoc FSUB_ZZZ_D %8, killed %92
    %107:zpr = nnan ninf nsz arcp contract afn reassoc FSUB_ZZZ_D %8, killed %89
    %108:zpr = nnan ninf nsz arcp contract afn reassoc FSUB_ZZZ_D %10, killed %98
    %109:zpr = nnan ninf nsz arcp contract afn reassoc FSUB_ZZZ_D %10, killed %95
    %110:zpr = nnan ninf nsz arcp contract afn reassoc FSUB_ZZZ_D %12, killed %104
    %111:zpr = nnan ninf nsz arcp contract afn reassoc FSUB_ZZZ_D %12, killed %101
    %112:zpr = nnan ninf nsz arcp contract afn reassoc FMUL_ZZZ_D %107, %107
    %113:zpr = nnan ninf nsz arcp contract afn reassoc FMUL_ZZZ_D %106, %106
    %114:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_UNDEF_D %88, killed %113, %109, %109
    %115:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_UNDEF_D %88, killed %112, %108, %108
    %116:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_UNDEF_D %88, killed %115, %111, %111
    %117:zpr = nnan ninf nsz arcp contract afn reassoc FMLA_ZPZZZ_UNDEF_D %88, killed %114, %110, %110
    %118:zpr = nnan ninf nsz arcp contract afn reassoc FSQRT_ZPmZ_UNDEF_D %119, %88, killed %117
    %120:zpr = nnan ninf nsz arcp contract afn reassoc FSQRT_ZPmZ_UNDEF_D %121, %88, killed %116
    %123:zpr = nnan ninf nsz arcp contract afn reassoc FDIV_ZPZZ_UNDEF_D %88, %122, killed %120
    %124:zpr = nnan ninf nsz arcp contract afn reassoc FDIV_ZPZZ_UNDEF_D %88, %122, killed %118
    %125:zpr = LD1W_IMM %83, %16, 0 :: (load unknown-size from %ir.lsr.iv98, align 4, !tbaa !10)
    %126:zpr = UUNPKHI_ZZ_D %125
    %127:zpr = FCVT_ZPmZ_StoD_UNDEF %128, %88, killed %126
    %129:zpr = UUNPKLO_ZZ_D %125
    %130:zpr = FCVT_ZPmZ_StoD_UNDEF %131, %88, killed %129
    %132:zpr = nnan ninf nsz arcp contract afn reassoc FADD_ZZZ_D killed %124, killed %130
    %133:zpr = nnan ninf nsz arcp contract afn reassoc FADD_ZZZ_D killed %123, killed %127
    %134:zpr = FCVT_ZPmZ_DtoS_UNDEF %135, %88, killed %133
    %136:zpr = FCVT_ZPmZ_DtoS_UNDEF %137, %88, killed %132
    %138:zpr = UZP1_ZZZ_S killed %136, killed %134
    ST1W_IMM killed %138, %83, %16, 0 :: (store unknown-size into %ir.lsr.iv98, align 4, !tbaa !10)
    %139:gpr64sp = ADDXri %19, 32, 0
    %21:gpr64all = COPY %139
    %140:gpr64sp = ADDXri %18, 32, 0
    %22:gpr64all = COPY %140
    %141:gpr64sp = ADDXri %17, 32, 0
    %23:gpr64all = COPY %141
    %142:gpr64sp = ADDXri %16, 32, 0
    %24:gpr64all = COPY %142
    %143:gpr64 = SUBSXri %20, 1, 0, implicit-def $nzcv
    %25:gpr64all = COPY %143
    Bcc 1, %bb.5, implicit $nzcv
    B %bb.6
  
  bb.6.middle.block:
    successors: %bb.9(0x40000000), %bb.7(0x40000000)
  
    dead $xzr = SUBSXrr %61, %1, implicit-def $nzcv
    Bcc 0, %bb.9, implicit $nzcv
    B %bb.7
  
  bb.7.for.body4.us.us.us.preheader:
    successors: %bb.8(0x80000000)
  
    %26:gpr64 = PHI %72, %bb.11, %6, %bb.6
    %145:gpr64 = nuw nsw UBFMXri %26, 62, 61
    %147:gpr64 = ADDXrr %55, %145
    %27:gpr64all = COPY %147
    %149:gpr64 = ADDXrr %57, %145
    %28:gpr64all = COPY %149
    %151:gpr64 = ADDXrr %59, %145
    %29:gpr64all = COPY %151
    %153:gpr64 = ADDXrr %184, %145
    %30:gpr64all = COPY %153
    %154:gpr64 = SUBXrr %1, %26
    %31:gpr64all = COPY %154
  
  bb.8.for.body4.us.us.us:
    successors: %bb.8(0x7c000000), %bb.9(0x04000000)
  
    %32:gpr64sp = PHI %30, %bb.7, %40, %bb.8
    %33:gpr64sp = PHI %29, %bb.7, %39, %bb.8
    %34:gpr64sp = PHI %28, %bb.7, %38, %bb.8
    %35:gpr64sp = PHI %27, %bb.7, %37, %bb.8
    %36:gpr64sp = PHI %31, %bb.7, %41, %bb.8
    early-clobber %155:gpr64sp, %156:fpr32 = LDRSpost %35, 4 :: (load (s32) from %ir.lsr.iv102, !tbaa !10)
    early-clobber %157:gpr64sp, %158:fpr32 = LDRSpost %34, 4 :: (load (s32) from %ir.lsr.iv105, !tbaa !10)
    early-clobber %159:gpr64sp, %160:fpr32 = LDRSpost %33, 4 :: (load (s32) from %ir.lsr.iv108, !tbaa !10)
    %161:fpr64 = nofpexcept FCVTDSr killed %156
    %162:fpr64 = nofpexcept FCVTDSr killed %158
    %163:fpr64 = nofpexcept FCVTDSr killed %160
    %164:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FSUBDrr %3, killed %161
    %165:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FSUBDrr %4, killed %162
    %166:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FSUBDrr %5, killed %163
    %167:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMULDrr %164, %164
    %169:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMADDDrrr %165, %165, killed %167
    %171:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FMADDDrrr %166, %166, killed %169
    %172:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FSQRTDr killed %171
    %174:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FDIVDrr %173, killed %172
    %175:fpr32 = LDRSui %32, 0 :: (load (s32) from %ir.lsr.iv111, !tbaa !10)
    %176:fpr64 = nofpexcept FCVTDSr killed %175
    %177:fpr64 = nnan ninf nsz arcp contract afn reassoc nofpexcept FADDDrr killed %174, killed %176
    %178:fpr32 = nofpexcept FCVTSDr killed %177
    early-clobber %179:gpr64sp = STRSpost killed %178, %32, 4 :: (store (s32) into %ir.lsr.iv111, !tbaa !10)
    %37:gpr64all = COPY %155
    %38:gpr64all = COPY %157
    %39:gpr64all = COPY %159
    %40:gpr64all = COPY %179
    %180:gpr64 = SUBSXri %36, 1, 0, implicit-def $nzcv
    %41:gpr64all = COPY %180
    Bcc 1, %bb.8, implicit $nzcv
    B %bb.9
  
  bb.9.for.cond1.for.cond.cleanup3_crit_edge.split.us.us.us:
    successors: %bb.10(0x04000000), %bb.3(0x7c000000)
  
    %181:gpr32common = nuw nsw ADDWri %14, 1, 0
    %42:gpr32all = COPY %181
    dead $wzr = SUBSWrr %181, %44, implicit-def $nzcv
    Bcc 1, %bb.3, implicit $nzcv
    B %bb.10
  
  bb.10.for.cond.cleanup:
    %183:gpr64common = MOVaddr target-flags(aarch64-page) @vx, target-flags(aarch64-pageoff, aarch64-nc) @vx
    $x0 = COPY %183

...
