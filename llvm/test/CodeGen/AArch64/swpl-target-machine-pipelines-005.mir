#RUN: llc %s -mcpu=a64fx -ffj-swp -O1 -swpl-debug -start-before=aarch64-swpipeliner -o /dev/null 2>&1 | FileCheck %s

#CHECK:DBG(AArch64SwplTargetMachine::getPipelines): Pseudo-instr: INSERT_SUBREG

#CHECK:DBG(AArch64SwplTargetMachine::getPipelines): MI: %170:zpr = FADDA_VPZ_D %25:ppr_3b, %169:zpr(tied-def 0), killed %165:zpr
#CHECK-NEXT:  ResourceID: SIMDFP_SVE_OP+14
#CHECK-NEXT:  latency: 72
#CHECK-NEXT:  seqDecode: true
#CHECK-NEXT:  stage/resource(): 0/FLA, 1/FLA, 7/FLA, 9/FLA, 13/FLA, 18/FLA, 19/FLA, 25/FLA, 27/FLA, 31/FLA, 36/FLA, 37/FLA, 45/FLA, 54/FLA, 63/FLA
#CHECK-NEXT:  stage/resource(): 0/FLB, 0/FLA, 6/FLA, 9/FLB, 12/FLA, 18/FLB, 18/FLA, 24/FLA, 27/FLB, 30/FLA, 36/FLB, 36/FLA, 45/FLB, 54/FLB, 63/FLB

--- |
  ; ModuleID = '/TSVC_2/src_sep_optnone/s311.c'
  source_filename = "/TSVC_2/src_sep_optnone/s311.c"
  target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
  target triple = "aarch64-unknown-linux-gnu"
  
  %struct.args_t = type { %struct.timeval, %struct.timeval, ptr }
  %struct.timeval = type { i64, i64 }
  
  @__func__.s311 = private unnamed_addr constant [5 x i8] c"s311\00", align 1
  @a = external global [32000 x double], align 64
  @b = external global [32000 x double], align 64
  @c = external global [32000 x double], align 64
  @d = external global [32000 x double], align 64
  @e = external global [32000 x double], align 64
  @aa = external global [256 x [256 x double]], align 64
  @bb = external global [256 x [256 x double]], align 64
  @cc = external global [256 x [256 x double]], align 64
  
  ; Function Attrs: nounwind uwtable vscale_range(4,4)
  define dso_local double @s311(ptr nocapture noundef %func_args) local_unnamed_addr #0 {
  entry:
    %call = tail call i32 @initialise_arrays(ptr noundef nonnull @__func__.s311) #6
    %call1 = tail call i32 @gettimeofday(ptr noundef %func_args, ptr noundef null) #6
    br label %vector.ph
  
  vector.ph:                                        ; preds = %for.cond.cleanup4, %entry
    %nl.019 = phi i32 [ 0, %entry ], [ %inc8, %for.cond.cleanup4 ]
    %0 = call i64 @llvm.start.loop.iterations.i64(i64 200)
    br label %vector.body
  
  vector.body:                                      ; preds = %vector.body, %vector.ph
    %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ 0, %vector.ph ]
    %vec.phi = phi double [ 0.000000e+00, %vector.ph ], [ %21, %vector.body ]
    %1 = phi i64 [ %0, %vector.ph ], [ %22, %vector.body ]
    %uglygep29 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep30 = getelementptr i8, ptr %uglygep29, i64 2304
    %uglygep31 = getelementptr i8, ptr %uglygep29, i64 2048
    %uglygep32 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep33 = getelementptr i8, ptr %uglygep32, i64 1792
    %uglygep34 = getelementptr i8, ptr %uglygep32, i64 1536
    %uglygep35 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep36 = getelementptr i8, ptr %uglygep35, i64 1280
    call void @llvm.prefetch.p0(ptr %uglygep36, i32 0, i32 3, i32 1)
    %wide.load = load <vscale x 2 x double>, ptr %uglygep35, align 64, !tbaa !6
    %uglygep65 = getelementptr i8, ptr %uglygep35, i64 64
    %wide.load22 = load <vscale x 2 x double>, ptr %uglygep65, align 64, !tbaa !6
    %uglygep63 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep64 = getelementptr i8, ptr %uglygep63, i64 128
    %wide.load23 = load <vscale x 2 x double>, ptr %uglygep64, align 64, !tbaa !6
    %uglygep61 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep62 = getelementptr i8, ptr %uglygep61, i64 192
    %wide.load24 = load <vscale x 2 x double>, ptr %uglygep62, align 64, !tbaa !6
    %2 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %vec.phi, <vscale x 2 x double> %wide.load)
    %3 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %2, <vscale x 2 x double> %wide.load22)
    %4 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %3, <vscale x 2 x double> %wide.load23)
    %5 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %4, <vscale x 2 x double> %wide.load24)
    %uglygep72 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep73 = getelementptr i8, ptr %uglygep72, i64 256
    call void @llvm.prefetch.p0(ptr %uglygep34, i32 0, i32 3, i32 1)
    %wide.load.1 = load <vscale x 2 x double>, ptr %uglygep73, align 64, !tbaa !6
    %uglygep70 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep71 = getelementptr i8, ptr %uglygep70, i64 320
    %wide.load22.1 = load <vscale x 2 x double>, ptr %uglygep71, align 64, !tbaa !6
    %uglygep68 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep69 = getelementptr i8, ptr %uglygep68, i64 384
    %wide.load23.1 = load <vscale x 2 x double>, ptr %uglygep69, align 64, !tbaa !6
    %uglygep66 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep67 = getelementptr i8, ptr %uglygep66, i64 448
    %wide.load24.1 = load <vscale x 2 x double>, ptr %uglygep67, align 64, !tbaa !6
    %6 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %5, <vscale x 2 x double> %wide.load.1)
    %7 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %6, <vscale x 2 x double> %wide.load22.1)
    %8 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %7, <vscale x 2 x double> %wide.load23.1)
    %9 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %8, <vscale x 2 x double> %wide.load24.1)
    %uglygep59 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep60 = getelementptr i8, ptr %uglygep59, i64 512
    call void @llvm.prefetch.p0(ptr %uglygep33, i32 0, i32 3, i32 1)
    %wide.load.2 = load <vscale x 2 x double>, ptr %uglygep60, align 64, !tbaa !6
    %uglygep57 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep58 = getelementptr i8, ptr %uglygep57, i64 576
    %wide.load22.2 = load <vscale x 2 x double>, ptr %uglygep58, align 64, !tbaa !6
    %uglygep55 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep56 = getelementptr i8, ptr %uglygep55, i64 640
    %wide.load23.2 = load <vscale x 2 x double>, ptr %uglygep56, align 64, !tbaa !6
    %uglygep53 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep54 = getelementptr i8, ptr %uglygep53, i64 704
    %wide.load24.2 = load <vscale x 2 x double>, ptr %uglygep54, align 64, !tbaa !6
    %10 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %9, <vscale x 2 x double> %wide.load.2)
    %11 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %10, <vscale x 2 x double> %wide.load22.2)
    %12 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %11, <vscale x 2 x double> %wide.load23.2)
    %13 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %12, <vscale x 2 x double> %wide.load24.2)
    %uglygep51 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep52 = getelementptr i8, ptr %uglygep51, i64 768
    call void @llvm.prefetch.p0(ptr %uglygep31, i32 0, i32 3, i32 1)
    %wide.load.3 = load <vscale x 2 x double>, ptr %uglygep52, align 64, !tbaa !6
    %uglygep49 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep50 = getelementptr i8, ptr %uglygep49, i64 832
    %wide.load22.3 = load <vscale x 2 x double>, ptr %uglygep50, align 64, !tbaa !6
    %uglygep47 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep48 = getelementptr i8, ptr %uglygep47, i64 896
    %wide.load23.3 = load <vscale x 2 x double>, ptr %uglygep48, align 64, !tbaa !6
    %uglygep45 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep46 = getelementptr i8, ptr %uglygep45, i64 960
    %wide.load24.3 = load <vscale x 2 x double>, ptr %uglygep46, align 64, !tbaa !6
    %14 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %13, <vscale x 2 x double> %wide.load.3)
    %15 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %14, <vscale x 2 x double> %wide.load22.3)
    %16 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %15, <vscale x 2 x double> %wide.load23.3)
    %17 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %16, <vscale x 2 x double> %wide.load24.3)
    %uglygep43 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep44 = getelementptr i8, ptr %uglygep43, i64 1024
    call void @llvm.prefetch.p0(ptr %uglygep30, i32 0, i32 3, i32 1)
    %wide.load.4 = load <vscale x 2 x double>, ptr %uglygep44, align 64, !tbaa !6
    %uglygep41 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep42 = getelementptr i8, ptr %uglygep41, i64 1088
    %wide.load22.4 = load <vscale x 2 x double>, ptr %uglygep42, align 64, !tbaa !6
    %uglygep39 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep40 = getelementptr i8, ptr %uglygep39, i64 1152
    %wide.load23.4 = load <vscale x 2 x double>, ptr %uglygep40, align 64, !tbaa !6
    %uglygep37 = getelementptr i8, ptr @a, i64 %lsr.iv
    %uglygep38 = getelementptr i8, ptr %uglygep37, i64 1216
    %wide.load24.4 = load <vscale x 2 x double>, ptr %uglygep38, align 64, !tbaa !6
    %18 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %17, <vscale x 2 x double> %wide.load.4)
    %19 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %18, <vscale x 2 x double> %wide.load22.4)
    %20 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %19, <vscale x 2 x double> %wide.load23.4)
    %21 = tail call double @llvm.vector.reduce.fadd.nxv2f64(double %20, <vscale x 2 x double> %wide.load24.4)
    %lsr.iv.next = add nuw nsw i64 %lsr.iv, 1280
    %22 = call i64 @llvm.loop.decrement.reg.i64(i64 %1, i64 1)
    %23 = icmp ne i64 %22, 0
    br i1 %23, label %vector.body, label %for.cond.cleanup4, !llvm.loop !10
  
  for.cond.cleanup:                                 ; preds = %for.cond.cleanup4
    %t2 = getelementptr inbounds %struct.args_t, ptr %func_args, i64 0, i32 1
    %call10 = tail call i32 @gettimeofday(ptr noundef nonnull %t2, ptr noundef null) #6
    %call11 = tail call double @calc_checksum(ptr noundef nonnull @__func__.s311) #6
    ret double %call11
  
  for.cond.cleanup4:                                ; preds = %vector.body
    %call6 = tail call i32 @dummy(ptr noundef nonnull @a, ptr noundef nonnull @b, ptr noundef nonnull @c, ptr noundef nonnull @d, ptr noundef nonnull @e, ptr noundef nonnull @aa, ptr noundef nonnull @bb, ptr noundef nonnull @cc, double noundef %21) #6
    %inc8 = add nuw nsw i32 %nl.019, 1
    %exitcond21.not = icmp eq i32 %inc8, 1000000
    br i1 %exitcond21.not, label %for.cond.cleanup, label %vector.ph, !llvm.loop !13
  }
  
  declare i32 @initialise_arrays(ptr noundef) local_unnamed_addr #1
  
  ; Function Attrs: nofree nounwind
  declare noundef i32 @gettimeofday(ptr nocapture noundef, ptr nocapture noundef) local_unnamed_addr #2
  
  declare i32 @dummy(ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, ptr noundef, double noundef) local_unnamed_addr #1
  
  declare double @calc_checksum(ptr noundef) local_unnamed_addr #1
  
  ; Function Attrs: nocallback nofree nosync nounwind readnone willreturn
  declare double @llvm.vector.reduce.fadd.nxv2f64(double, <vscale x 2 x double>) #3
  
  ; Function Attrs: inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn
  declare void @llvm.prefetch.p0(ptr nocapture readonly, i32 immarg, i32 immarg, i32) #4
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.start.loop.iterations.i64(i64) #5
  
  ; Function Attrs: nocallback noduplicate nofree nosync nounwind willreturn
  declare i64 @llvm.loop.decrement.reg.i64(i64, i64) #5
  
  attributes #0 = { nounwind uwtable vscale_range(4,4) "frame-pointer"="non-leaf" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+crypto,+fp-armv8,+fullfp16,+lse,+neon,+outline-atomics,+ras,+rdm,+sha2,+sve,+v8.2a" }
  attributes #1 = { "frame-pointer"="non-leaf" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+crypto,+fp-armv8,+fullfp16,+lse,+neon,+outline-atomics,+ras,+rdm,+sha2,+sve,+v8.2a" }
  attributes #2 = { nofree nounwind "frame-pointer"="non-leaf" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="a64fx" "target-features"="+aes,+crc,+crypto,+fp-armv8,+fullfp16,+lse,+neon,+outline-atomics,+ras,+rdm,+sha2,+sve,+v8.2a" }
  attributes #3 = { nocallback nofree nosync nounwind readnone willreturn }
  attributes #4 = { inaccessiblemem_or_argmemonly nocallback nofree nosync nounwind willreturn }
  attributes #5 = { nocallback noduplicate nofree nosync nounwind willreturn }
  attributes #6 = { nounwind }
  
  !llvm.module.flags = !{!0, !1, !2, !3, !4}
  
  !0 = !{i32 1, !"wchar_size", i32 4}
  !1 = !{i32 7, !"PIC Level", i32 2}
  !2 = !{i32 7, !"PIE Level", i32 2}
  !3 = !{i32 7, !"uwtable", i32 2}
  !4 = !{i32 7, !"frame-pointer", i32 1}
  !6 = !{!7, !7, i64 0}
  !7 = !{!"double", !8, i64 0}
  !8 = !{!"omnipotent char", !9, i64 0}
  !9 = !{!"Simple C/C++ TBAA"}
  !10 = distinct !{!10, !11, !12}
  !11 = !{!"llvm.loop.mustprogress"}
  !12 = !{!"llvm.loop.isvectorized", i32 1}
  !13 = distinct !{!13, !11}

...
---
name:            s311
alignment:       8
exposesReturnsTwice: false
legalized:       false
regBankSelected: false
selected:        false
failedISel:      false
tracksRegLiveness: true
hasWinCFI:       false
callsEHReturn:   false
callsUnwindInit: false
hasEHCatchret:   false
hasEHScopes:     false
hasEHFunclets:   false
failsVerification: false
tracksDebugUserValues: false
registers:
  - { id: 0, class: gpr32sp, preferred-register: '' }
  - { id: 1, class: gpr64all, preferred-register: '' }
  - { id: 2, class: gpr64common, preferred-register: '' }
  - { id: 3, class: fpr64, preferred-register: '' }
  - { id: 4, class: gpr64sp, preferred-register: '' }
  - { id: 5, class: fpr64, preferred-register: '' }
  - { id: 6, class: gpr64all, preferred-register: '' }
  - { id: 7, class: gpr64all, preferred-register: '' }
  - { id: 8, class: gpr32all, preferred-register: '' }
  - { id: 9, class: gpr64common, preferred-register: '' }
  - { id: 10, class: gpr32all, preferred-register: '' }
  - { id: 11, class: gpr64common, preferred-register: '' }
  - { id: 12, class: gpr32all, preferred-register: '' }
  - { id: 13, class: gpr64all, preferred-register: '' }
  - { id: 14, class: gpr32all, preferred-register: '' }
  - { id: 15, class: gpr32all, preferred-register: '' }
  - { id: 16, class: gpr64all, preferred-register: '' }
  - { id: 17, class: fpr64, preferred-register: '' }
  - { id: 18, class: gpr64all, preferred-register: '' }
  - { id: 19, class: gpr32, preferred-register: '' }
  - { id: 20, class: gpr64common, preferred-register: '' }
  - { id: 21, class: gpr64common, preferred-register: '' }
  - { id: 22, class: ppr_3b, preferred-register: '' }
  - { id: 23, class: zpr, preferred-register: '' }
  - { id: 24, class: gpr64common, preferred-register: '' }
  - { id: 25, class: ppr_3b, preferred-register: '' }
  - { id: 26, class: zpr, preferred-register: '' }
  - { id: 27, class: gpr64common, preferred-register: '' }
  - { id: 28, class: zpr, preferred-register: '' }
  - { id: 29, class: gpr64common, preferred-register: '' }
  - { id: 30, class: zpr, preferred-register: '' }
  - { id: 31, class: zpr, preferred-register: '' }
  - { id: 32, class: zpr, preferred-register: '' }
  - { id: 33, class: ppr_3b, preferred-register: '' }
  - { id: 34, class: zpr, preferred-register: '' }
  - { id: 35, class: fpr64, preferred-register: '' }
  - { id: 36, class: zpr, preferred-register: '' }
  - { id: 37, class: zpr, preferred-register: '' }
  - { id: 38, class: zpr, preferred-register: '' }
  - { id: 39, class: fpr64, preferred-register: '' }
  - { id: 40, class: zpr, preferred-register: '' }
  - { id: 41, class: zpr, preferred-register: '' }
  - { id: 42, class: zpr, preferred-register: '' }
  - { id: 43, class: fpr64, preferred-register: '' }
  - { id: 44, class: zpr, preferred-register: '' }
  - { id: 45, class: zpr, preferred-register: '' }
  - { id: 46, class: zpr, preferred-register: '' }
  - { id: 47, class: fpr64, preferred-register: '' }
  - { id: 48, class: gpr64common, preferred-register: '' }
  - { id: 49, class: zpr, preferred-register: '' }
  - { id: 50, class: gpr64common, preferred-register: '' }
  - { id: 51, class: zpr, preferred-register: '' }
  - { id: 52, class: gpr64common, preferred-register: '' }
  - { id: 53, class: zpr, preferred-register: '' }
  - { id: 54, class: gpr64common, preferred-register: '' }
  - { id: 55, class: zpr, preferred-register: '' }
  - { id: 56, class: zpr, preferred-register: '' }
  - { id: 57, class: zpr, preferred-register: '' }
  - { id: 58, class: zpr, preferred-register: '' }
  - { id: 59, class: fpr64, preferred-register: '' }
  - { id: 60, class: zpr, preferred-register: '' }
  - { id: 61, class: zpr, preferred-register: '' }
  - { id: 62, class: zpr, preferred-register: '' }
  - { id: 63, class: fpr64, preferred-register: '' }
  - { id: 64, class: zpr, preferred-register: '' }
  - { id: 65, class: zpr, preferred-register: '' }
  - { id: 66, class: zpr, preferred-register: '' }
  - { id: 67, class: fpr64, preferred-register: '' }
  - { id: 68, class: zpr, preferred-register: '' }
  - { id: 69, class: zpr, preferred-register: '' }
  - { id: 70, class: zpr, preferred-register: '' }
  - { id: 71, class: fpr64, preferred-register: '' }
  - { id: 72, class: gpr64common, preferred-register: '' }
  - { id: 73, class: zpr, preferred-register: '' }
  - { id: 74, class: gpr64common, preferred-register: '' }
  - { id: 75, class: zpr, preferred-register: '' }
  - { id: 76, class: gpr64common, preferred-register: '' }
  - { id: 77, class: zpr, preferred-register: '' }
  - { id: 78, class: gpr64common, preferred-register: '' }
  - { id: 79, class: zpr, preferred-register: '' }
  - { id: 80, class: zpr, preferred-register: '' }
  - { id: 81, class: zpr, preferred-register: '' }
  - { id: 82, class: zpr, preferred-register: '' }
  - { id: 83, class: fpr64, preferred-register: '' }
  - { id: 84, class: zpr, preferred-register: '' }
  - { id: 85, class: zpr, preferred-register: '' }
  - { id: 86, class: zpr, preferred-register: '' }
  - { id: 87, class: fpr64, preferred-register: '' }
  - { id: 88, class: zpr, preferred-register: '' }
  - { id: 89, class: zpr, preferred-register: '' }
  - { id: 90, class: zpr, preferred-register: '' }
  - { id: 91, class: fpr64, preferred-register: '' }
  - { id: 92, class: zpr, preferred-register: '' }
  - { id: 93, class: zpr, preferred-register: '' }
  - { id: 94, class: zpr, preferred-register: '' }
  - { id: 95, class: fpr64, preferred-register: '' }
  - { id: 96, class: gpr64common, preferred-register: '' }
  - { id: 97, class: zpr, preferred-register: '' }
  - { id: 98, class: gpr64common, preferred-register: '' }
  - { id: 99, class: zpr, preferred-register: '' }
  - { id: 100, class: gpr64common, preferred-register: '' }
  - { id: 101, class: zpr, preferred-register: '' }
  - { id: 102, class: gpr64common, preferred-register: '' }
  - { id: 103, class: zpr, preferred-register: '' }
  - { id: 104, class: zpr, preferred-register: '' }
  - { id: 105, class: zpr, preferred-register: '' }
  - { id: 106, class: zpr, preferred-register: '' }
  - { id: 107, class: fpr64, preferred-register: '' }
  - { id: 108, class: zpr, preferred-register: '' }
  - { id: 109, class: zpr, preferred-register: '' }
  - { id: 110, class: zpr, preferred-register: '' }
  - { id: 111, class: fpr64, preferred-register: '' }
  - { id: 112, class: zpr, preferred-register: '' }
  - { id: 113, class: zpr, preferred-register: '' }
  - { id: 114, class: zpr, preferred-register: '' }
  - { id: 115, class: fpr64, preferred-register: '' }
  - { id: 116, class: zpr, preferred-register: '' }
  - { id: 117, class: zpr, preferred-register: '' }
  - { id: 118, class: zpr, preferred-register: '' }
  - { id: 119, class: fpr64, preferred-register: '' }
  - { id: 120, class: gpr64common, preferred-register: '' }
  - { id: 121, class: zpr, preferred-register: '' }
  - { id: 122, class: gpr64common, preferred-register: '' }
  - { id: 123, class: zpr, preferred-register: '' }
  - { id: 124, class: gpr64common, preferred-register: '' }
  - { id: 125, class: zpr, preferred-register: '' }
  - { id: 126, class: gpr64common, preferred-register: '' }
  - { id: 127, class: zpr, preferred-register: '' }
  - { id: 128, class: zpr, preferred-register: '' }
  - { id: 129, class: zpr, preferred-register: '' }
  - { id: 130, class: zpr, preferred-register: '' }
  - { id: 131, class: fpr64, preferred-register: '' }
  - { id: 132, class: zpr, preferred-register: '' }
  - { id: 133, class: zpr, preferred-register: '' }
  - { id: 134, class: zpr, preferred-register: '' }
  - { id: 135, class: fpr64, preferred-register: '' }
  - { id: 136, class: zpr, preferred-register: '' }
  - { id: 137, class: zpr, preferred-register: '' }
  - { id: 138, class: zpr, preferred-register: '' }
  - { id: 139, class: fpr64, preferred-register: '' }
  - { id: 140, class: zpr, preferred-register: '' }
  - { id: 141, class: zpr, preferred-register: '' }
  - { id: 142, class: zpr, preferred-register: '' }
  - { id: 143, class: gpr64sp, preferred-register: '' }
  - { id: 144, class: gpr64, preferred-register: '' }
  - { id: 145, class: gpr64common, preferred-register: '' }
  - { id: 146, class: gpr64common, preferred-register: '' }
  - { id: 147, class: gpr64common, preferred-register: '' }
  - { id: 148, class: gpr64common, preferred-register: '' }
  - { id: 149, class: gpr64common, preferred-register: '' }
  - { id: 150, class: gpr64common, preferred-register: '' }
  - { id: 151, class: gpr64common, preferred-register: '' }
  - { id: 152, class: gpr64common, preferred-register: '' }
  - { id: 153, class: gpr32all, preferred-register: '' }
  - { id: 154, class: gpr32common, preferred-register: '' }
  - { id: 155, class: gpr32, preferred-register: '' }
  - { id: 156, class: gpr32, preferred-register: '' }
  - { id: 157, class: gpr64sp, preferred-register: '' }
  - { id: 158, class: gpr64all, preferred-register: '' }
  - { id: 159, class: gpr32all, preferred-register: '' }
  - { id: 160, class: gpr64common, preferred-register: '' }
liveins:
  - { reg: '$x0', virtual-reg: '%9' }
frameInfo:
  isFrameAddressTaken: false
  isReturnAddressTaken: false
  hasStackMap:     false
  hasPatchPoint:   false
  stackSize:       0
  offsetAdjustment: 0
  maxAlignment:    1
  adjustsStack:    true
  hasCalls:        true
  stackProtector:  ''
  functionContext: ''
  maxCallFrameSize: 0
  cvBytesOfCalleeSavedRegisters: 0
  hasOpaqueSPAdjustment: false
  hasVAStart:      false
  hasMustTailInVarArgFunc: false
  hasTailCall:     true
  localFrameSize:  0
  savePoint:       ''
  restorePoint:    ''
fixedStack:      []
stack:           []
callSites:       []
debugValueSubstitutions: []
constants:       []
machineFunctionInfo: {}
body:             |
  bb.0.entry:
    successors: %bb.1(0x80000000)
    liveins: $x0
  
    %9:gpr64common = COPY $x0
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    %11:gpr64common = MOVaddr target-flags(aarch64-page) @__func__.s311, target-flags(aarch64-pageoff, aarch64-nc) @__func__.s311
    $x0 = COPY %11
    BL @initialise_arrays, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    %13:gpr64all = COPY $xzr
    $x0 = COPY %9
    $x1 = COPY %13
    BL @gettimeofday, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit $x1, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    %15:gpr32all = COPY $wzr
    %10:gpr32all = COPY %15
    %19:gpr32 = MOVi32imm 200
    %20:gpr64common = LOADgot target-flags(aarch64-got) @a
    %22:ppr_3b = PTRUE_B 31
    %24:gpr64common = MOVi64imm 8
    %25:ppr_3b = PTRUE_D 31
    %27:gpr64common = MOVi64imm 16
    %29:gpr64common = MOVi64imm 24
    %32:zpr = IMPLICIT_DEF
    %37:zpr = IMPLICIT_DEF
    %41:zpr = IMPLICIT_DEF
    %45:zpr = IMPLICIT_DEF
    %48:gpr64common = MOVi64imm 32
    %50:gpr64common = MOVi64imm 40
    %52:gpr64common = MOVi64imm 48
    %54:gpr64common = MOVi64imm 56
    %57:zpr = IMPLICIT_DEF
    %61:zpr = IMPLICIT_DEF
    %65:zpr = IMPLICIT_DEF
    %69:zpr = IMPLICIT_DEF
    %72:gpr64common = MOVi64imm 64
    %74:gpr64common = MOVi64imm 72
    %76:gpr64common = MOVi64imm 80
    %78:gpr64common = MOVi64imm 88
    %81:zpr = IMPLICIT_DEF
    %85:zpr = IMPLICIT_DEF
    %89:zpr = IMPLICIT_DEF
    %93:zpr = IMPLICIT_DEF
    %96:gpr64common = MOVi64imm 96
    %98:gpr64common = MOVi64imm 104
    %100:gpr64common = MOVi64imm 112
    %102:gpr64common = MOVi64imm 120
    %105:zpr = IMPLICIT_DEF
    %109:zpr = IMPLICIT_DEF
    %113:zpr = IMPLICIT_DEF
    %117:zpr = IMPLICIT_DEF
    %120:gpr64common = MOVi64imm 128
    %122:gpr64common = MOVi64imm 136
    %124:gpr64common = MOVi64imm 144
    %126:gpr64common = MOVi64imm 152
    %129:zpr = IMPLICIT_DEF
    %133:zpr = IMPLICIT_DEF
    %137:zpr = IMPLICIT_DEF
    %141:zpr = IMPLICIT_DEF
    %146:gpr64common = LOADgot target-flags(aarch64-got) @b
    %147:gpr64common = LOADgot target-flags(aarch64-got) @c
    %148:gpr64common = LOADgot target-flags(aarch64-got) @d
    %149:gpr64common = LOADgot target-flags(aarch64-got) @e
    %150:gpr64common = LOADgot target-flags(aarch64-got) @aa
    %151:gpr64common = LOADgot target-flags(aarch64-got) @bb
    %152:gpr64common = LOADgot target-flags(aarch64-got) @cc
    %155:gpr32 = MOVi32imm 1000000
  
  bb.1.vector.ph:
    successors: %bb.2(0x80000000)
  
    %0:gpr32sp = PHI %10, %bb.0, %8, %bb.4
    %17:fpr64 = FMOVD0
    %18:gpr64all = COPY $xzr
    %16:gpr64all = COPY %18
    %1:gpr64all = SUBREG_TO_REG 0, %19, %subreg.sub_32
  
  bb.2.vector.body:
    successors: %bb.2(0x7c000000), %bb.4(0x04000000)
  
    %2:gpr64common = PHI %16, %bb.1, %6, %bb.2
    %3:fpr64 = PHI %17, %bb.1, %5, %bb.2
    %4:gpr64sp = PHI %1, %bb.1, %7, %bb.2
    %21:gpr64common = ADDXrr %20, %2
    PRFMui 0, %21, 160
    %23:zpr = LD1B %22, %20, %2 :: (load unknown-size from %ir.uglygep35, align 64, !tbaa !6)
    %26:zpr = LD1D %25, %21, %24 :: (load unknown-size from %ir.uglygep65, align 64, !tbaa !6)
    %28:zpr = LD1D %25, %21, %27 :: (load unknown-size from %ir.uglygep64, align 64, !tbaa !6)
    %30:zpr = LD1D %25, %21, %29 :: (load unknown-size from %ir.uglygep62, align 64, !tbaa !6)
    %31:zpr = INSERT_SUBREG %32, %3, %subreg.dsub
    %34:zpr = FADDA_VPZ_D %25, %31, killed %23
    %35:fpr64 = COPY %34.dsub
    %36:zpr = INSERT_SUBREG %37, killed %35, %subreg.dsub
    %38:zpr = FADDA_VPZ_D %25, %36, killed %26
    %39:fpr64 = COPY %38.dsub
    %40:zpr = INSERT_SUBREG %41, killed %39, %subreg.dsub
    %42:zpr = FADDA_VPZ_D %25, %40, killed %28
    %43:fpr64 = COPY %42.dsub
    %44:zpr = INSERT_SUBREG %45, killed %43, %subreg.dsub
    %46:zpr = FADDA_VPZ_D %25, %44, killed %30
    %47:fpr64 = COPY %46.dsub
    PRFMui 0, %21, 192
    %49:zpr = LD1D %25, %21, %48 :: (load unknown-size from %ir.uglygep73, align 64, !tbaa !6)
    %51:zpr = LD1D %25, %21, %50 :: (load unknown-size from %ir.uglygep71, align 64, !tbaa !6)
    %53:zpr = LD1D %25, %21, %52 :: (load unknown-size from %ir.uglygep69, align 64, !tbaa !6)
    %55:zpr = LD1D %25, %21, %54 :: (load unknown-size from %ir.uglygep67, align 64, !tbaa !6)
    %56:zpr = INSERT_SUBREG %57, killed %47, %subreg.dsub
    %58:zpr = FADDA_VPZ_D %25, %56, killed %49
    %59:fpr64 = COPY %58.dsub
    %60:zpr = INSERT_SUBREG %61, killed %59, %subreg.dsub
    %62:zpr = FADDA_VPZ_D %25, %60, killed %51
    %63:fpr64 = COPY %62.dsub
    %64:zpr = INSERT_SUBREG %65, killed %63, %subreg.dsub
    %66:zpr = FADDA_VPZ_D %25, %64, killed %53
    %67:fpr64 = COPY %66.dsub
    %68:zpr = INSERT_SUBREG %69, killed %67, %subreg.dsub
    %70:zpr = FADDA_VPZ_D %25, %68, killed %55
    %71:fpr64 = COPY %70.dsub
    PRFMui 0, %21, 224
    %73:zpr = LD1D %25, %21, %72 :: (load unknown-size from %ir.uglygep60, align 64, !tbaa !6)
    %75:zpr = LD1D %25, %21, %74 :: (load unknown-size from %ir.uglygep58, align 64, !tbaa !6)
    %77:zpr = LD1D %25, %21, %76 :: (load unknown-size from %ir.uglygep56, align 64, !tbaa !6)
    %79:zpr = LD1D %25, %21, %78 :: (load unknown-size from %ir.uglygep54, align 64, !tbaa !6)
    %80:zpr = INSERT_SUBREG %81, killed %71, %subreg.dsub
    %82:zpr = FADDA_VPZ_D %25, %80, killed %73
    %83:fpr64 = COPY %82.dsub
    %84:zpr = INSERT_SUBREG %85, killed %83, %subreg.dsub
    %86:zpr = FADDA_VPZ_D %25, %84, killed %75
    %87:fpr64 = COPY %86.dsub
    %88:zpr = INSERT_SUBREG %89, killed %87, %subreg.dsub
    %90:zpr = FADDA_VPZ_D %25, %88, killed %77
    %91:fpr64 = COPY %90.dsub
    %92:zpr = INSERT_SUBREG %93, killed %91, %subreg.dsub
    %94:zpr = FADDA_VPZ_D %25, %92, killed %79
    %95:fpr64 = COPY %94.dsub
    PRFMui 0, %21, 256
    %97:zpr = LD1D %25, %21, %96 :: (load unknown-size from %ir.uglygep52, align 64, !tbaa !6)
    %99:zpr = LD1D %25, %21, %98 :: (load unknown-size from %ir.uglygep50, align 64, !tbaa !6)
    %101:zpr = LD1D %25, %21, %100 :: (load unknown-size from %ir.uglygep48, align 64, !tbaa !6)
    %103:zpr = LD1D %25, %21, %102 :: (load unknown-size from %ir.uglygep46, align 64, !tbaa !6)
    %104:zpr = INSERT_SUBREG %105, killed %95, %subreg.dsub
    %106:zpr = FADDA_VPZ_D %25, %104, killed %97
    %107:fpr64 = COPY %106.dsub
    %108:zpr = INSERT_SUBREG %109, killed %107, %subreg.dsub
    %110:zpr = FADDA_VPZ_D %25, %108, killed %99
    %111:fpr64 = COPY %110.dsub
    %112:zpr = INSERT_SUBREG %113, killed %111, %subreg.dsub
    %114:zpr = FADDA_VPZ_D %25, %112, killed %101
    %115:fpr64 = COPY %114.dsub
    %116:zpr = INSERT_SUBREG %117, killed %115, %subreg.dsub
    %118:zpr = FADDA_VPZ_D %25, %116, killed %103
    %119:fpr64 = COPY %118.dsub
    PRFMui 0, %21, 288
    %121:zpr = LD1D %25, %21, %120 :: (load unknown-size from %ir.uglygep44, align 64, !tbaa !6)
    %123:zpr = LD1D %25, %21, %122 :: (load unknown-size from %ir.uglygep42, align 64, !tbaa !6)
    %125:zpr = LD1D %25, %21, %124 :: (load unknown-size from %ir.uglygep40, align 64, !tbaa !6)
    %127:zpr = LD1D %25, %21, %126 :: (load unknown-size from %ir.uglygep38, align 64, !tbaa !6)
    %128:zpr = INSERT_SUBREG %129, killed %119, %subreg.dsub
    %130:zpr = FADDA_VPZ_D %25, %128, killed %121
    %131:fpr64 = COPY %130.dsub
    %132:zpr = INSERT_SUBREG %133, killed %131, %subreg.dsub
    %134:zpr = FADDA_VPZ_D %25, %132, killed %123
    %135:fpr64 = COPY %134.dsub
    %136:zpr = INSERT_SUBREG %137, killed %135, %subreg.dsub
    %138:zpr = FADDA_VPZ_D %25, %136, killed %125
    %139:fpr64 = COPY %138.dsub
    %140:zpr = INSERT_SUBREG %141, killed %139, %subreg.dsub
    %142:zpr = FADDA_VPZ_D %25, %140, killed %127
    %5:fpr64 = COPY %142.dsub
    %143:gpr64sp = nuw nsw ADDXri %2, 1280, 0
    %6:gpr64all = COPY %143
    %144:gpr64 = SUBSXri %4, 1, 0, implicit-def $nzcv
    %7:gpr64all = COPY %144
    Bcc 1, %bb.2, implicit $nzcv
    B %bb.4
  
  bb.3.for.cond.cleanup:
    %157:gpr64sp = nuw ADDXri %9, 16, 0
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    %158:gpr64all = COPY $xzr
    $x0 = COPY %157
    $x1 = COPY %158
    BL @gettimeofday, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit $x1, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    %160:gpr64common = MOVaddr target-flags(aarch64-page) @__func__.s311, target-flags(aarch64-pageoff, aarch64-nc) @__func__.s311
    $x0 = COPY %160
    TCRETURNdi @calc_checksum, 0, csr_aarch64_aapcs, implicit $sp, implicit $x0
  
  bb.4.for.cond.cleanup4:
    successors: %bb.3(0x04000000), %bb.1(0x7c000000)
  
    ADJCALLSTACKDOWN 0, 0, implicit-def dead $sp, implicit $sp
    $x0 = COPY %20
    $x1 = COPY %146
    $x2 = COPY %147
    $x3 = COPY %148
    $x4 = COPY %149
    $x5 = COPY %150
    $x6 = COPY %151
    $x7 = COPY %152
    $d0 = COPY %5
    BL @dummy, csr_aarch64_aapcs, implicit-def dead $lr, implicit $sp, implicit $x0, implicit $x1, implicit $x2, implicit $x3, implicit $x4, implicit $x5, implicit $x6, implicit $x7, implicit $d0, implicit-def $sp, implicit-def $w0
    ADJCALLSTACKUP 0, 0, implicit-def dead $sp, implicit $sp
    %154:gpr32common = nuw nsw ADDWri %0, 1, 0
    %8:gpr32all = COPY %154
    dead $wzr = SUBSWrr %154, %155, implicit-def $nzcv
    Bcc 0, %bb.3, implicit $nzcv
    B %bb.1

...
